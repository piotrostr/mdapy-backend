{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Total MDA: A Python-based Tool for Calculating and Evaluating MDAs from Detrital Geo-Thermochronologic Data<center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Morgan D. Brooks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Version 1.0.0</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Modules and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import Required Modules\n",
    "\n",
    "First, execute the following by selecting the cell and return+shift: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MDA_Functions as MDAFunc\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import math \n",
    "import peakutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Download Excel File to Input Data & Load Data to Notebook\n",
    "\n",
    "This is where you will load your excel file of data. This step must by run initially, and should be repeated if any changes are made to the dataset in Excel. This step will load data from a CSV into a DataFrame; into a variable called df. \n",
    "\n",
    "1. Open the excel file in the MDA_Tool Directory (same loaction as this Jupyter file) titled: \"Data_Upload\"\n",
    "2. Opent the excel file and fill in 2 Sheets titled: \"Samples\" and \"Data\"\n",
    "3. For the \"Samples\" sheet: you MUST fill in the Sample_ID column with all the individual samples, but the \"Unit\" and \"Basin\" columns can be left blank\n",
    "4. The \"Data\" sheet must have the following columns filled in: \n",
    "    - Sample_ID\n",
    "    - BestAge\n",
    "    - BestAge_err_sx (can be 1sigma or 2sigma)\n",
    "    - At least one ratio and error: 207/206, 206/208, or 207/235 \n",
    "    - The remaining columns can be left blank \n",
    "5. Save the file as a .csv and close it \n",
    "4. Press return+shift in the cell below to load your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Functions for loading a dataset and selecting samples \n",
    "###############################################################\n",
    "\n",
    "def loadData(samples_df, analyses_df, ID_col = 'Sample_ID'):\n",
    "    \"\"\"\n",
    "    Creates a Pandas DataFrame from DataFrames of samples and analyses\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : A Pandas DataFrame that contains sample information.\n",
    "    analyses : A Pandas DataFrame that contains analysis information.\n",
    "    ID_col : (optional) The name of the column that contains unique sample identifiers. Default is 'Sample_ID'\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    main_byid_df : A Pandas DataFrame indexed by Sample_ID\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Portions of this script were provided by Kevin Befus (University of Wyoming)\n",
    "\n",
    "    \"\"\"\n",
    "    main_byid_df = None\n",
    "    analyses_df.set_index('Sample_ID',inplace=True,drop=False)\n",
    "    samples_df.set_index('Sample_ID',inplace=True,drop=False)\n",
    "    main_byid_df = samples_df.copy() # Samples table is the starting point\n",
    "\n",
    "    for sample in main_byid_df[ID_col]: # loop through entries in main_df\n",
    "        if sample in analyses_df[ID_col]: # Allows samples to exist without analyses data\n",
    "            active_UPb_data = analyses_df.loc[analyses_df[ID_col].isin([sample]),:]\n",
    "            for colname in active_UPb_data:\n",
    "                if colname not in [ID_col]: # Skip if the indexing column\n",
    "                    # Check column naming overlap with the Samples table (having the same column name will otherwise result in an error)\n",
    "                    if colname in samples_df.columns:\n",
    "                        colname_adj = colname+'_data' # New name for colname\n",
    "                        if colname_adj not in main_byid_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_byid_df[colname_adj] = (np.nan*np.empty(shape=(len(main_byid_df),1))).tolist()\n",
    "                            main_byid_df[colname_adj] = np.asarray(main_byid_df[colname_adj])                \n",
    "                        main_byid_df.at[sample,colname_adj] = active_UPb_data[colname].values\n",
    "                    else:\n",
    "                        if colname not in main_byid_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_byid_df[colname] = (np.nan*np.empty(shape=(len(main_byid_df),1))).tolist()\n",
    "                            main_byid_df[colname] = np.asarray(main_byid_df[colname])\n",
    "                        main_byid_df.at[sample,colname] = active_UPb_data[colname].values\n",
    "        else:\n",
    "            for colname in analyses_df.columns:\n",
    "                if colname not in [ID_col]:\n",
    "                    if colname in samples_df.columns:\n",
    "                        colname_adj = colname+'_data' # New name for colname\n",
    "                        if colname_adj not in main_byid_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_byid_df[colname_adj] = (np.nan*np.empty(shape=(len(main_byid_df),1))).tolist()\n",
    "                            main_byid_df[colname_adj] = np.asarray(main_byid_df[colname_adj])                \n",
    "                        main_byid_df.at[sample,colname_adj] = []\n",
    "                    else:\n",
    "                        if colname not in main_byid_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_byid_df[colname] = (np.nan*np.empty(shape=(len(main_byid_df),1))).tolist()\n",
    "                            main_byid_df[colname] = np.asarray(main_byid_df[colname])\n",
    "                        main_byid_df.at[sample,colname] = []       \n",
    "    return main_byid_df\n",
    "\n",
    "def loadDataExcel(dataToPlot, mainSheet = 'Samples', dataSheet = 'Data', ID_col = 'Sample_ID'):\n",
    "    \"\"\"\n",
    "    Loads an Excel file containing detrital geochronologic and/or thermochronologic data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataToPlot : An array with the full filePath of each data file to be loaded, including the directory, file name, and extension\n",
    "    mainSheet : (optional) The name of the Excel worksheet that contains sample information. The default name is 'Samples'\n",
    "    dataSheet : (optional) The name of the Excel worksheet that contains grain analysis information. The default name is 'ZrUPb'\n",
    "    ID_col : (optional) The name of the column that contains unique sample identifiers. Default is 'Sample_ID'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    main_df : the database\n",
    "    main_byid_df : the database indexed by sample name\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Portions of this script were provided by Kevin Befus (University of Wyoming)\n",
    "    \"\"\"    \n",
    "    \n",
    "    obj1 = []\n",
    "    obj2 = []\n",
    "    obj3 = []\n",
    "    obj4 = []\n",
    "    for i in range(len(dataToPlot)):\n",
    "        dfs = pd.read_excel(dataToPlot[i],sheet_name=None)\n",
    "        main_df = None\n",
    "        main_df = dfs[mainSheet]\n",
    "        samples_df = main_df.copy()\n",
    "        analyses_df = dfs[dataSheet]\n",
    "    \n",
    "        for sample_ind in range(main_df.shape[0]): # loop through entries in main_df\n",
    "            active_sample_id = main_df.loc[sample_ind,ID_col]\n",
    "            active_UPb_data = dfs[dataSheet].loc[dfs[dataSheet][ID_col].isin([active_sample_id]),:]\n",
    "            for colname in active_UPb_data:\n",
    "                if colname not in [ID_col]: # Skip if the indexing column\n",
    "                    # Check column naming overlap with the Samples table (having the same column name will otherwise result in an error)\n",
    "                    if colname in samples_df.columns:\n",
    "                        colname_adj = colname+'_'+dataSheet # New name for colname\n",
    "                        if colname_adj not in main_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_df[colname_adj] = (np.nan*np.empty(shape=(len(main_df),1))).tolist()\n",
    "                            main_df[colname_adj] = np.asarray(main_df[colname_adj])                \n",
    "                        main_df.at[sample_ind,colname_adj] = active_UPb_data[colname].values\n",
    "                    else:\n",
    "                        if colname not in main_df.columns: # Make colname with revised name if already in samples table\n",
    "                            main_df[colname] = (np.nan*np.empty(shape=(len(main_df),1))).tolist()\n",
    "                            main_df[colname] = np.asarray(main_df[colname])\n",
    "                        main_df.at[sample_ind,colname] = active_UPb_data[colname].values\n",
    "    \n",
    "        # Make a copy of the dataset and set the sample ID as index\n",
    "        main_byid_df = main_df.copy()\n",
    "        main_byid_df.set_index(ID_col,inplace=True,drop=False)\n",
    "        obj1.append(main_df)\n",
    "        obj2.append(main_byid_df)\n",
    "        obj3.append(samples_df)\n",
    "        obj4.append(analyses_df)\n",
    "    main_df = pd.concat(obj1, sort=False)\n",
    "    main_byid_df = pd.concat(obj2, sort=False)\n",
    "    samples_df = pd.concat(obj3, sort=False)\n",
    "    analyses_df = pd.concat(obj4, sort=False)\n",
    "    \n",
    "    return main_df, main_byid_df, samples_df, analyses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Basin</th>\n",
       "      <th>207Pb/206Pb</th>\n",
       "      <th>207Pb/206Pb err</th>\n",
       "      <th>206Pb/238U</th>\n",
       "      <th>206Pb/238U err</th>\n",
       "      <th>207Pb/235Pb</th>\n",
       "      <th>207Pb/235Pb err</th>\n",
       "      <th>75Age</th>\n",
       "      <th>...</th>\n",
       "      <th>68Age</th>\n",
       "      <th>68Age_err</th>\n",
       "      <th>76Age</th>\n",
       "      <th>76Age_err</th>\n",
       "      <th>BestAge</th>\n",
       "      <th>BestAge_err_sx</th>\n",
       "      <th>BestAge_err_stotal</th>\n",
       "      <th>U_ppm</th>\n",
       "      <th>U_Th</th>\n",
       "      <th>Th_U</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POR-2</th>\n",
       "      <td>POR-2</td>\n",
       "      <td>Point of Rocks Ss</td>\n",
       "      <td>San Joaquin basin</td>\n",
       "      <td>[0.0406881889456608, 0.04602798541712321, 0.04...</td>\n",
       "      <td>[0.005552522773590929, 0.007519798305100781, 0...</td>\n",
       "      <td>[0.006687861050854221, 0.0072719567694101645, ...</td>\n",
       "      <td>[0.00012506301931104475, 0.0001018074277218713...</td>\n",
       "      <td>[0.037519485628478996, 0.04615030015640152, 0....</td>\n",
       "      <td>[0.005167952957787695, 0.007567414000591077, 0...</td>\n",
       "      <td>[37.39935449561242, 45.81108363542066, 47.6174...</td>\n",
       "      <td>...</td>\n",
       "      <td>[42.96919594561263, 46.708419534945264, 48.226...</td>\n",
       "      <td>[0.800852038337176, 0.6515547700251538, 0.9993...</td>\n",
       "      <td>[-307.07890707133015, -0.8928101005134416, 17....</td>\n",
       "      <td>[350.5904941293329, 396.0820325790396, 41.2019...</td>\n",
       "      <td>[42.96919594561263, 46.708419534945264, 48.226...</td>\n",
       "      <td>[0.800852038337176, 0.6515547700251538, 0.9993...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.627621449689062, 0.4961071900646707, 0.0520...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POR-3</th>\n",
       "      <td>POR-3</td>\n",
       "      <td>Point of Rocks Ss</td>\n",
       "      <td>San Joaquin basin</td>\n",
       "      <td>[0.04670790060262111, 0.047672351283777774, 0....</td>\n",
       "      <td>[0.011743393592522144, 0.008033745500213678, 0...</td>\n",
       "      <td>[0.007026652857469043, 0.013299217102483786, 0...</td>\n",
       "      <td>[0.0010746806645855179, 0.000494826248668319, ...</td>\n",
       "      <td>[0.045252244022150404, 0.08741660243827779, 0....</td>\n",
       "      <td>[0.013317138402255946, 0.015086234083045016, 0...</td>\n",
       "      <td>[44.93906496242438, 85.09396723053692, 89.2389...</td>\n",
       "      <td>...</td>\n",
       "      <td>[45.13831407280074, 85.16718033964855, 86.8715...</td>\n",
       "      <td>[6.8794994529228966, 3.1479894061072287, 1.769...</td>\n",
       "      <td>[34.3248370021054, 83.01650526932218, 153.0324...</td>\n",
       "      <td>[610.3829868966902, 402.33668293556605, 73.693...</td>\n",
       "      <td>[45.13831407280074, 85.16718033964855, 86.8715...</td>\n",
       "      <td>[6.8794994529228966, 3.1479894061072287, 1.769...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.9837507073194807, 0.2970781234307026, 0.858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUT-5</th>\n",
       "      <td>BUT-5</td>\n",
       "      <td>Butano Ss</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.05762354763728019, 0.03641110633769712, 0.0...</td>\n",
       "      <td>[0.011269888448444877, 0.010694335370449353, 0...</td>\n",
       "      <td>[0.01248059231288972, 0.01259869011900655, 0.0...</td>\n",
       "      <td>[0.0007166957165695656, 0.0008100399909659366,...</td>\n",
       "      <td>[0.09915998766360977, 0.06325000202868346, 0.0...</td>\n",
       "      <td>[0.02021217639564266, 0.019017116096352923, 0....</td>\n",
       "      <td>[96.00065035127058, 62.273703670211894, 85.301...</td>\n",
       "      <td>...</td>\n",
       "      <td>[79.95714249032814, 80.70902156952796, 82.3027...</td>\n",
       "      <td>[4.563167174061512, 5.156884411054435, 1.38264...</td>\n",
       "      <td>[515.4568924560183, -599.9301958570051, 170.06...</td>\n",
       "      <td>[433.2945978448812, 812.5849145152981, 159.693...</td>\n",
       "      <td>[79.95714249032814, 80.70902156952796, 82.3027...</td>\n",
       "      <td>[4.563167174061512, 5.156884411054435, 1.38264...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[1.2867765283029227, 0.7227353978942941, 0.733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POR-1</th>\n",
       "      <td>POR-1</td>\n",
       "      <td>Point of Rocks Ss</td>\n",
       "      <td>San Joaquin basin</td>\n",
       "      <td>[0.04806541191382841, 0.042734788224866385, 0....</td>\n",
       "      <td>[0.004940324799540449, 0.013156269746160855, 0...</td>\n",
       "      <td>[0.006760606112963907, 0.012732052609210369, 0...</td>\n",
       "      <td>[0.0001265067265072234, 0.0015769994338613196,...</td>\n",
       "      <td>[0.04480428767161959, 0.07502072473666914, 0.0...</td>\n",
       "      <td>[0.004680830620337464, 0.024894938561114112, 0...</td>\n",
       "      <td>[44.50381616700174, 73.45274937157997, 82.1040...</td>\n",
       "      <td>...</td>\n",
       "      <td>[43.43500851336782, 81.55797905712907, 84.2409...</td>\n",
       "      <td>[0.8100384095577873, 10.038192931921522, 3.583...</td>\n",
       "      <td>[102.48489961586091, -183.0155274310181, 20.37...</td>\n",
       "      <td>[243.56638391351234, 784.5500500306964, 289.45...</td>\n",
       "      <td>[43.43500851336782, 81.55797905712907, 84.2409...</td>\n",
       "      <td>[0.8100384095577873, 10.038192931921522, 3.583...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[2.5070011249322732, 0.6143287549109991, 0.361...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUT-4</th>\n",
       "      <td>BUT-4</td>\n",
       "      <td>Butano Ss</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.04403926770363514, 0.030833277207446743, 0....</td>\n",
       "      <td>[0.002433447237794016, 0.014109664979674537, 0...</td>\n",
       "      <td>[0.013426569876481128, 0.013593183541357957, 0...</td>\n",
       "      <td>[0.00032212652355915984, 0.0004563999175794958...</td>\n",
       "      <td>[0.08152793455158856, 0.05778859599665868, 0.1...</td>\n",
       "      <td>[0.004911245762445431, 0.02651581667101828, 0....</td>\n",
       "      <td>[79.58043918232099, 57.044726326365975, 107.69...</td>\n",
       "      <td>...</td>\n",
       "      <td>[85.97732321618626, 87.03706690423192, 87.1322...</td>\n",
       "      <td>[2.0490493554891245, 2.9026863518950847, 11.61...</td>\n",
       "      <td>[-108.47398511641335, -1075.494766231362, 590....</td>\n",
       "      <td>[136.07972415269364, 1441.1587890762612, 1163....</td>\n",
       "      <td>[85.97732321618626, 87.03706690423192, 87.1322...</td>\n",
       "      <td>[2.0490493554891245, 2.9026863518950847, 11.61...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.5459033832726942, 0.8891614267348487, 0.793...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJB-1</th>\n",
       "      <td>SJB-1</td>\n",
       "      <td>San Juan Bautista Fm</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.046858824827988164, 0.04832247749171772, 0....</td>\n",
       "      <td>[0.003805081375262937, 0.00396701518526671, 0....</td>\n",
       "      <td>[0.012970045650468305, 0.013561930555566523, 0...</td>\n",
       "      <td>[0.0001469470979993244, 0.0005130111276947163,...</td>\n",
       "      <td>[0.08379810007453242, 0.09035911806407121, 0.0...</td>\n",
       "      <td>[0.006870577861103175, 0.0081675995911402, 0.0...</td>\n",
       "      <td>[81.70953051341182, 87.83785154372454, 92.1166...</td>\n",
       "      <td>...</td>\n",
       "      <td>[83.07271483667525, 86.83829603617806, 87.0112...</td>\n",
       "      <td>[0.9351528875660051, 3.262832188011892, 2.4624...</td>\n",
       "      <td>[42.02327500469606, 115.0647220463812, 226.466...</td>\n",
       "      <td>[194.43094236269678, 193.91190139527237, 346.0...</td>\n",
       "      <td>[83.07271483667525, 86.83829603617806, 87.0112...</td>\n",
       "      <td>[0.9351528875660051, 3.262832188011892, 2.4624...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.704392609979317, 0.8704321658914768, 0.9760...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUT-3</th>\n",
       "      <td>BUT-3</td>\n",
       "      <td>Butano Ss</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.05446, 0.0506, 0.0512, 0.0731, 0.0519, 0.05...</td>\n",
       "      <td>[0.00065, 0.0006999999999999999, 0.00075, 0.00...</td>\n",
       "      <td>[0.01056, 0.01218, 0.01245, 0.01324, 0.01317, ...</td>\n",
       "      <td>[0.00016000000000000004, 0.000165, 0.00016, 0....</td>\n",
       "      <td>[0.0797, 0.0864, 0.0878, 0.1331, 0.0931, 0.096...</td>\n",
       "      <td>[0.0015000000000000002, 0.0016, 0.00155, 0.005...</td>\n",
       "      <td>[61.1, 54.0, 61.0, -30.0, 67.0, 57.0, 48.0, 87...</td>\n",
       "      <td>...</td>\n",
       "      <td>[67.11326049864458, 77.74625164294953, 79.4024...</td>\n",
       "      <td>[1.0148008159231676, 1.0511750429816773, 1.018...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[67.11326049864458, 77.74625164294953, 79.4024...</td>\n",
       "      <td>[1.0148008159231676, 1.0511750429816773, 1.018...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.32894736842105265, 0.3205128205128205, 0.45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUT-2</th>\n",
       "      <td>BUT-2</td>\n",
       "      <td>Butano Ss</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.0495, 0.0485, 0.0541, 0.0525, 0.048, 0.0461...</td>\n",
       "      <td>[0.0006, 0.0006, 0.0014000000000000002, 0.0012...</td>\n",
       "      <td>[0.01208, 0.01272, 0.01316, 0.01383, 0.0138, 0...</td>\n",
       "      <td>[0.00015000000000000001, 0.0001649999999999999...</td>\n",
       "      <td>[0.0807, 0.0839, 0.0973, 0.0991, 0.0904, 0.087...</td>\n",
       "      <td>[0.00145, 0.0016, 0.0028000000000000004, 0.002...</td>\n",
       "      <td>[60.0, 85.0, 31.0, 85.0, 90.0, 50.0, 57.0, 103...</td>\n",
       "      <td>...</td>\n",
       "      <td>[77.21743369794198, 81.39340264826086, 83.6042...</td>\n",
       "      <td>[0.9567358980816547, 1.0531143014578779, 1.210...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[77.21743369794198, 81.39340264826086, 83.6042...</td>\n",
       "      <td>[0.9567358980816547, 1.0531143014578779, 1.210...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.18615040953090098, 0.29325513196480935, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEJ-2</th>\n",
       "      <td>TEJ-2</td>\n",
       "      <td>Tejon Fm</td>\n",
       "      <td>San Joaquin basin</td>\n",
       "      <td>[0.04815, 0.05122, 0.053, 0.0486, 0.0482, 0.05...</td>\n",
       "      <td>[0.000285, 0.00037500000000000006, 0.00095, 0....</td>\n",
       "      <td>[0.009758, 0.01099, 0.01271, 0.01299, 0.01309,...</td>\n",
       "      <td>[0.00010999999999999999, 0.00021, 0.000155, 0....</td>\n",
       "      <td>[0.06505, 0.076, 0.0931, 0.0863, 0.086, 0.0909...</td>\n",
       "      <td>[0.0008500000000000001, 0.0013499999999999999,...</td>\n",
       "      <td>[68.6, 66.6, 66.0, 73.0, 40.0, 57.0, 73.0, 88....</td>\n",
       "      <td>...</td>\n",
       "      <td>[62.5294364021132, 70.12316161605732, 80.86974...</td>\n",
       "      <td>[0.7029273399467104, 1.3354256250764396, 0.986...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[62.5294364021132, 70.12316161605732, 80.86974...</td>\n",
       "      <td>[0.7029273399467104, 1.3354256250764396, 0.986...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.04642525533890437, 0.13175230566534915, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEJ-1</th>\n",
       "      <td>TEJ-1</td>\n",
       "      <td>Tejon Fm</td>\n",
       "      <td>San Joaquin basin</td>\n",
       "      <td>[0.0492, 0.0487, 0.0477, 0.063, 0.0487, 0.0481...</td>\n",
       "      <td>[0.00095, 0.0009000000000000001, 0.0011, 0.000...</td>\n",
       "      <td>[0.01332, 0.01332, 0.01337, 0.01374, 0.01365, ...</td>\n",
       "      <td>[0.00017, 0.00017, 0.00018, 0.0001750000000000...</td>\n",
       "      <td>[0.0912, 0.0916, 0.0892, 0.1202, 0.0925, 0.090...</td>\n",
       "      <td>[0.00215, 0.0020499999999999997, 0.00245, 0.00...</td>\n",
       "      <td>[29.0, 15.0, -64.0, 57.0, -49.0, 1.0, 84.0, 61...</td>\n",
       "      <td>...</td>\n",
       "      <td>[85.1407481711587, 85.19426504155912, 85.62006...</td>\n",
       "      <td>[1.0865748407891955, 1.086761419952321, 1.1536...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[85.1407481711587, 85.19426504155912, 85.62006...</td>\n",
       "      <td>[1.0865748407891955, 1.086761419952321, 1.1536...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.40966816878328555, 0.2901915264074289, 0.73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEF-1</th>\n",
       "      <td>SEF-1</td>\n",
       "      <td>San Emigdio Fm</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.04742, 0.0483, 0.0539, 0.0505, 0.0493, 0.04...</td>\n",
       "      <td>[0.0005, 0.0005499999999999999, 0.000900000000...</td>\n",
       "      <td>[0.01245, 0.01264, 0.01313, 0.01329, 0.01331, ...</td>\n",
       "      <td>[0.00015500000000000003, 0.00015, 0.00017, 0.0...</td>\n",
       "      <td>[0.0823, 0.0838, 0.0992, 0.0929, 0.0907, 0.087...</td>\n",
       "      <td>[0.0014500000000000001, 0.00145, 0.00209999999...</td>\n",
       "      <td>[88.6, 81.3, 84.0, 94.0, 77.0, 64.0, 70.0, 101...</td>\n",
       "      <td>...</td>\n",
       "      <td>[79.78104362747698, 80.90398224501742, 83.4355...</td>\n",
       "      <td>[0.990386022399871, 0.957672654271169, 1.07976...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[79.78104362747698, 80.90398224501742, 83.4355...</td>\n",
       "      <td>[0.990386022399871, 0.957672654271169, 1.07976...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.28851702250432776, 0.5091649694501018, 0.42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUT-1</th>\n",
       "      <td>BUT-1</td>\n",
       "      <td>Butano Ss</td>\n",
       "      <td>La Honda basin</td>\n",
       "      <td>[0.0472, 0.0506, 0.0492, 0.0494, 0.0488, 0.049...</td>\n",
       "      <td>[0.0014000000000000002, 0.0018000000000000002,...</td>\n",
       "      <td>[0.01278, 0.01293, 0.01311, 0.01363, 0.01363, ...</td>\n",
       "      <td>[0.00013499999999999997, 0.000145, 0.000110000...</td>\n",
       "      <td>[0.0822, 0.0908, 0.0902, 0.0914, 0.0914, 0.093...</td>\n",
       "      <td>[0.0025, 0.0032999999999999995, 0.0019, 0.0029...</td>\n",
       "      <td>[79.0, 50.0, 115.0, 156.0, 78.0, 81.0, 91.0, 8...</td>\n",
       "      <td>...</td>\n",
       "      <td>[81.90928404046831, 82.51307664719889, 83.8042...</td>\n",
       "      <td>[0.8734683094459214, 0.9401437964593449, 0.707...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[81.90928404046831, 82.51307664719889, 83.8042...</td>\n",
       "      <td>[0.8734683094459214, 0.9401437964593449, 0.707...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.40535062829347385, 0.46382189239332094, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11-Escanilla</th>\n",
       "      <td>11-Escanilla</td>\n",
       "      <td>Escanilla</td>\n",
       "      <td>Ainsa Basin</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.04485, 0.0451, 0.04535, 0.04566, 0.04585, 0...</td>\n",
       "      <td>[0.000235, 0.0005, 0.00043, 0.000305, 0.000285...</td>\n",
       "      <td>[0.3246, 0.3291, 0.3371, 0.3274, 0.3468, 0.345...</td>\n",
       "      <td>[0.0022, 0.004, 0.0036, 0.00285, 0.00305, 0.00...</td>\n",
       "      <td>[285.8, 288.8, 294.7, 287.4, 302.8, 300.8, 292...</td>\n",
       "      <td>...</td>\n",
       "      <td>[282.8, 284.6, 285.9, 287.8, 289.0, 294.3, 294...</td>\n",
       "      <td>[1.45, 3.15, 2.65, 1.9, 1.75, 2.7, 2.05, 1.8, ...</td>\n",
       "      <td>[310.0, 325.0, 336.0, 281.0, 410.0, 309.0, 262...</td>\n",
       "      <td>[14.5, 27.0, 18.5, 22.0, 26.0, 21.5, 22.5, 20....</td>\n",
       "      <td>[282.8, 284.6, 285.9, 287.8, 289.0, 294.3, 294...</td>\n",
       "      <td>[1.45, 3.15, 2.65, 1.9, 1.75, 2.7, 2.05, 1.8, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[580.0, 941.0, 598.0, 186.9, 148.1, 191.8, 180...</td>\n",
       "      <td>[3.26, 33.2, 3.74, 1.28, 1.87, 1.62, 1.2, 1.34...</td>\n",
       "      <td>[0.3067484662576687, 0.03012048192771084, 0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12-Escanilla</th>\n",
       "      <td>12-Escanilla</td>\n",
       "      <td>Escanilla</td>\n",
       "      <td>Ainsa Basin</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.04717, 0.04718, 0.04731, 0.04733, 0.04855, ...</td>\n",
       "      <td>[0.000465, 0.00028, 0.00036, 0.00036, 0.000365...</td>\n",
       "      <td>[0.3478, 0.3387, 0.3652, 0.3505, 0.3561, 0.357...</td>\n",
       "      <td>[0.0039, 0.0025, 0.0035, 0.0032, 0.00375, 0.00...</td>\n",
       "      <td>[302.7, 296.1, 316.7, 304.9, 309.0, 310.5, 310...</td>\n",
       "      <td>...</td>\n",
       "      <td>[297.1, 297.1, 298.0, 298.1, 305.6, 306.4, 307...</td>\n",
       "      <td>[2.85, 1.75, 2.2, 2.2, 2.25, 2.0, 2.3, 2.55, 1...</td>\n",
       "      <td>[345.0, 277.0, 409.0, 354.0, 330.0, 324.0, 326...</td>\n",
       "      <td>[26.5, 20.0, 22.0, 21.0, 24.5, 27.0, 22.0, 29....</td>\n",
       "      <td>[297.1, 297.1, 298.0, 298.1, 305.6, 306.4, 307...</td>\n",
       "      <td>[2.85, 1.75, 2.2, 2.2, 2.25, 2.0, 2.3, 2.55, 1...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[152.0, 340.0, 130.6, 360.0, 127.0, 166.0, 199...</td>\n",
       "      <td>[1.94, 1.72, 1.11, 1.82, 1.39, 1.64, 1.9, 1.64...</td>\n",
       "      <td>[0.5154639175257733, 0.5813953488372093, 0.900...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10-Sobrarbe</th>\n",
       "      <td>10-Sobrarbe</td>\n",
       "      <td>Sobrarbe</td>\n",
       "      <td>Ainsa Basin</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[0.04495, 0.0452, 0.04546, 0.04551, 0.04592, 0...</td>\n",
       "      <td>[0.00036, 0.0005, 0.00028, 0.00041, 0.000435, ...</td>\n",
       "      <td>[0.332, 0.3249, 0.3285, 0.3302, 0.3378, 0.3348...</td>\n",
       "      <td>[0.0065, 0.00365, 0.0025, 0.0031, 0.0039, 0.00...</td>\n",
       "      <td>[291.0, 285.5, 288.3, 289.5, 297.0, 293.0, 295...</td>\n",
       "      <td>...</td>\n",
       "      <td>[283.4, 285.0, 286.5, 286.9, 289.4, 290.2, 291...</td>\n",
       "      <td>[2.25, 3.2, 1.7, 2.5, 2.7, 2.15, 2.15, 1.95, 2...</td>\n",
       "      <td>[373.0, 301.0, 282.0, 302.0, 326.0, 296.0, 300...</td>\n",
       "      <td>[47.5, 23.5, 21.5, 17.0, 29.0, 22.0, 19.0, 19....</td>\n",
       "      <td>[283.4, 285.0, 286.5, 286.9, 289.4, 290.2, 291...</td>\n",
       "      <td>[2.25, 3.2, 1.7, 2.5, 2.7, 2.15, 2.15, 1.95, 2...</td>\n",
       "      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n",
       "      <td>[197.0, 697.0, 289.0, 701.0, 266.0, 319.0, 228...</td>\n",
       "      <td>[2.02, 1.83, 1.17, 2.29, 1.52, 1.79, 1.85, 1.4...</td>\n",
       "      <td>[0.49504950495049505, 0.5464480874316939, 0.85...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Sample_ID                  Unit              Basin  \\\n",
       "Sample_ID                                                             \n",
       "POR-2                POR-2     Point of Rocks Ss  San Joaquin basin   \n",
       "POR-3                POR-3     Point of Rocks Ss  San Joaquin basin   \n",
       "BUT-5                BUT-5             Butano Ss     La Honda basin   \n",
       "POR-1                POR-1     Point of Rocks Ss  San Joaquin basin   \n",
       "BUT-4                BUT-4             Butano Ss     La Honda basin   \n",
       "SJB-1                SJB-1  San Juan Bautista Fm     La Honda basin   \n",
       "BUT-3                BUT-3             Butano Ss     La Honda basin   \n",
       "BUT-2                BUT-2             Butano Ss     La Honda basin   \n",
       "TEJ-2                TEJ-2              Tejon Fm  San Joaquin basin   \n",
       "TEJ-1                TEJ-1              Tejon Fm  San Joaquin basin   \n",
       "SEF-1                SEF-1        San Emigdio Fm     La Honda basin   \n",
       "BUT-1                BUT-1             Butano Ss     La Honda basin   \n",
       "11-Escanilla  11-Escanilla             Escanilla        Ainsa Basin   \n",
       "12-Escanilla  12-Escanilla             Escanilla        Ainsa Basin   \n",
       "10-Sobrarbe    10-Sobrarbe              Sobrarbe        Ainsa Basin   \n",
       "\n",
       "                                                    207Pb/206Pb  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.0406881889456608, 0.04602798541712321, 0.04...   \n",
       "POR-3         [0.04670790060262111, 0.047672351283777774, 0....   \n",
       "BUT-5         [0.05762354763728019, 0.03641110633769712, 0.0...   \n",
       "POR-1         [0.04806541191382841, 0.042734788224866385, 0....   \n",
       "BUT-4         [0.04403926770363514, 0.030833277207446743, 0....   \n",
       "SJB-1         [0.046858824827988164, 0.04832247749171772, 0....   \n",
       "BUT-3         [0.05446, 0.0506, 0.0512, 0.0731, 0.0519, 0.05...   \n",
       "BUT-2         [0.0495, 0.0485, 0.0541, 0.0525, 0.048, 0.0461...   \n",
       "TEJ-2         [0.04815, 0.05122, 0.053, 0.0486, 0.0482, 0.05...   \n",
       "TEJ-1         [0.0492, 0.0487, 0.0477, 0.063, 0.0487, 0.0481...   \n",
       "SEF-1         [0.04742, 0.0483, 0.0539, 0.0505, 0.0493, 0.04...   \n",
       "BUT-1         [0.0472, 0.0506, 0.0492, 0.0494, 0.0488, 0.049...   \n",
       "11-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "12-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "10-Sobrarbe   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "\n",
       "                                                207Pb/206Pb err  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.005552522773590929, 0.007519798305100781, 0...   \n",
       "POR-3         [0.011743393592522144, 0.008033745500213678, 0...   \n",
       "BUT-5         [0.011269888448444877, 0.010694335370449353, 0...   \n",
       "POR-1         [0.004940324799540449, 0.013156269746160855, 0...   \n",
       "BUT-4         [0.002433447237794016, 0.014109664979674537, 0...   \n",
       "SJB-1         [0.003805081375262937, 0.00396701518526671, 0....   \n",
       "BUT-3         [0.00065, 0.0006999999999999999, 0.00075, 0.00...   \n",
       "BUT-2         [0.0006, 0.0006, 0.0014000000000000002, 0.0012...   \n",
       "TEJ-2         [0.000285, 0.00037500000000000006, 0.00095, 0....   \n",
       "TEJ-1         [0.00095, 0.0009000000000000001, 0.0011, 0.000...   \n",
       "SEF-1         [0.0005, 0.0005499999999999999, 0.000900000000...   \n",
       "BUT-1         [0.0014000000000000002, 0.0018000000000000002,...   \n",
       "11-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "12-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "10-Sobrarbe   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "\n",
       "                                                     206Pb/238U  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.006687861050854221, 0.0072719567694101645, ...   \n",
       "POR-3         [0.007026652857469043, 0.013299217102483786, 0...   \n",
       "BUT-5         [0.01248059231288972, 0.01259869011900655, 0.0...   \n",
       "POR-1         [0.006760606112963907, 0.012732052609210369, 0...   \n",
       "BUT-4         [0.013426569876481128, 0.013593183541357957, 0...   \n",
       "SJB-1         [0.012970045650468305, 0.013561930555566523, 0...   \n",
       "BUT-3         [0.01056, 0.01218, 0.01245, 0.01324, 0.01317, ...   \n",
       "BUT-2         [0.01208, 0.01272, 0.01316, 0.01383, 0.0138, 0...   \n",
       "TEJ-2         [0.009758, 0.01099, 0.01271, 0.01299, 0.01309,...   \n",
       "TEJ-1         [0.01332, 0.01332, 0.01337, 0.01374, 0.01365, ...   \n",
       "SEF-1         [0.01245, 0.01264, 0.01313, 0.01329, 0.01331, ...   \n",
       "BUT-1         [0.01278, 0.01293, 0.01311, 0.01363, 0.01363, ...   \n",
       "11-Escanilla  [0.04485, 0.0451, 0.04535, 0.04566, 0.04585, 0...   \n",
       "12-Escanilla  [0.04717, 0.04718, 0.04731, 0.04733, 0.04855, ...   \n",
       "10-Sobrarbe   [0.04495, 0.0452, 0.04546, 0.04551, 0.04592, 0...   \n",
       "\n",
       "                                                 206Pb/238U err  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.00012506301931104475, 0.0001018074277218713...   \n",
       "POR-3         [0.0010746806645855179, 0.000494826248668319, ...   \n",
       "BUT-5         [0.0007166957165695656, 0.0008100399909659366,...   \n",
       "POR-1         [0.0001265067265072234, 0.0015769994338613196,...   \n",
       "BUT-4         [0.00032212652355915984, 0.0004563999175794958...   \n",
       "SJB-1         [0.0001469470979993244, 0.0005130111276947163,...   \n",
       "BUT-3         [0.00016000000000000004, 0.000165, 0.00016, 0....   \n",
       "BUT-2         [0.00015000000000000001, 0.0001649999999999999...   \n",
       "TEJ-2         [0.00010999999999999999, 0.00021, 0.000155, 0....   \n",
       "TEJ-1         [0.00017, 0.00017, 0.00018, 0.0001750000000000...   \n",
       "SEF-1         [0.00015500000000000003, 0.00015, 0.00017, 0.0...   \n",
       "BUT-1         [0.00013499999999999997, 0.000145, 0.000110000...   \n",
       "11-Escanilla  [0.000235, 0.0005, 0.00043, 0.000305, 0.000285...   \n",
       "12-Escanilla  [0.000465, 0.00028, 0.00036, 0.00036, 0.000365...   \n",
       "10-Sobrarbe   [0.00036, 0.0005, 0.00028, 0.00041, 0.000435, ...   \n",
       "\n",
       "                                                    207Pb/235Pb  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.037519485628478996, 0.04615030015640152, 0....   \n",
       "POR-3         [0.045252244022150404, 0.08741660243827779, 0....   \n",
       "BUT-5         [0.09915998766360977, 0.06325000202868346, 0.0...   \n",
       "POR-1         [0.04480428767161959, 0.07502072473666914, 0.0...   \n",
       "BUT-4         [0.08152793455158856, 0.05778859599665868, 0.1...   \n",
       "SJB-1         [0.08379810007453242, 0.09035911806407121, 0.0...   \n",
       "BUT-3         [0.0797, 0.0864, 0.0878, 0.1331, 0.0931, 0.096...   \n",
       "BUT-2         [0.0807, 0.0839, 0.0973, 0.0991, 0.0904, 0.087...   \n",
       "TEJ-2         [0.06505, 0.076, 0.0931, 0.0863, 0.086, 0.0909...   \n",
       "TEJ-1         [0.0912, 0.0916, 0.0892, 0.1202, 0.0925, 0.090...   \n",
       "SEF-1         [0.0823, 0.0838, 0.0992, 0.0929, 0.0907, 0.087...   \n",
       "BUT-1         [0.0822, 0.0908, 0.0902, 0.0914, 0.0914, 0.093...   \n",
       "11-Escanilla  [0.3246, 0.3291, 0.3371, 0.3274, 0.3468, 0.345...   \n",
       "12-Escanilla  [0.3478, 0.3387, 0.3652, 0.3505, 0.3561, 0.357...   \n",
       "10-Sobrarbe   [0.332, 0.3249, 0.3285, 0.3302, 0.3378, 0.3348...   \n",
       "\n",
       "                                                207Pb/235Pb err  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.005167952957787695, 0.007567414000591077, 0...   \n",
       "POR-3         [0.013317138402255946, 0.015086234083045016, 0...   \n",
       "BUT-5         [0.02021217639564266, 0.019017116096352923, 0....   \n",
       "POR-1         [0.004680830620337464, 0.024894938561114112, 0...   \n",
       "BUT-4         [0.004911245762445431, 0.02651581667101828, 0....   \n",
       "SJB-1         [0.006870577861103175, 0.0081675995911402, 0.0...   \n",
       "BUT-3         [0.0015000000000000002, 0.0016, 0.00155, 0.005...   \n",
       "BUT-2         [0.00145, 0.0016, 0.0028000000000000004, 0.002...   \n",
       "TEJ-2         [0.0008500000000000001, 0.0013499999999999999,...   \n",
       "TEJ-1         [0.00215, 0.0020499999999999997, 0.00245, 0.00...   \n",
       "SEF-1         [0.0014500000000000001, 0.00145, 0.00209999999...   \n",
       "BUT-1         [0.0025, 0.0032999999999999995, 0.0019, 0.0029...   \n",
       "11-Escanilla  [0.0022, 0.004, 0.0036, 0.00285, 0.00305, 0.00...   \n",
       "12-Escanilla  [0.0039, 0.0025, 0.0035, 0.0032, 0.00375, 0.00...   \n",
       "10-Sobrarbe   [0.0065, 0.00365, 0.0025, 0.0031, 0.0039, 0.00...   \n",
       "\n",
       "                                                          75Age  ...  \\\n",
       "Sample_ID                                                        ...   \n",
       "POR-2         [37.39935449561242, 45.81108363542066, 47.6174...  ...   \n",
       "POR-3         [44.93906496242438, 85.09396723053692, 89.2389...  ...   \n",
       "BUT-5         [96.00065035127058, 62.273703670211894, 85.301...  ...   \n",
       "POR-1         [44.50381616700174, 73.45274937157997, 82.1040...  ...   \n",
       "BUT-4         [79.58043918232099, 57.044726326365975, 107.69...  ...   \n",
       "SJB-1         [81.70953051341182, 87.83785154372454, 92.1166...  ...   \n",
       "BUT-3         [61.1, 54.0, 61.0, -30.0, 67.0, 57.0, 48.0, 87...  ...   \n",
       "BUT-2         [60.0, 85.0, 31.0, 85.0, 90.0, 50.0, 57.0, 103...  ...   \n",
       "TEJ-2         [68.6, 66.6, 66.0, 73.0, 40.0, 57.0, 73.0, 88....  ...   \n",
       "TEJ-1         [29.0, 15.0, -64.0, 57.0, -49.0, 1.0, 84.0, 61...  ...   \n",
       "SEF-1         [88.6, 81.3, 84.0, 94.0, 77.0, 64.0, 70.0, 101...  ...   \n",
       "BUT-1         [79.0, 50.0, 115.0, 156.0, 78.0, 81.0, 91.0, 8...  ...   \n",
       "11-Escanilla  [285.8, 288.8, 294.7, 287.4, 302.8, 300.8, 292...  ...   \n",
       "12-Escanilla  [302.7, 296.1, 316.7, 304.9, 309.0, 310.5, 310...  ...   \n",
       "10-Sobrarbe   [291.0, 285.5, 288.3, 289.5, 297.0, 293.0, 295...  ...   \n",
       "\n",
       "                                                          68Age  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [42.96919594561263, 46.708419534945264, 48.226...   \n",
       "POR-3         [45.13831407280074, 85.16718033964855, 86.8715...   \n",
       "BUT-5         [79.95714249032814, 80.70902156952796, 82.3027...   \n",
       "POR-1         [43.43500851336782, 81.55797905712907, 84.2409...   \n",
       "BUT-4         [85.97732321618626, 87.03706690423192, 87.1322...   \n",
       "SJB-1         [83.07271483667525, 86.83829603617806, 87.0112...   \n",
       "BUT-3         [67.11326049864458, 77.74625164294953, 79.4024...   \n",
       "BUT-2         [77.21743369794198, 81.39340264826086, 83.6042...   \n",
       "TEJ-2         [62.5294364021132, 70.12316161605732, 80.86974...   \n",
       "TEJ-1         [85.1407481711587, 85.19426504155912, 85.62006...   \n",
       "SEF-1         [79.78104362747698, 80.90398224501742, 83.4355...   \n",
       "BUT-1         [81.90928404046831, 82.51307664719889, 83.8042...   \n",
       "11-Escanilla  [282.8, 284.6, 285.9, 287.8, 289.0, 294.3, 294...   \n",
       "12-Escanilla  [297.1, 297.1, 298.0, 298.1, 305.6, 306.4, 307...   \n",
       "10-Sobrarbe   [283.4, 285.0, 286.5, 286.9, 289.4, 290.2, 291...   \n",
       "\n",
       "                                                      68Age_err  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.800852038337176, 0.6515547700251538, 0.9993...   \n",
       "POR-3         [6.8794994529228966, 3.1479894061072287, 1.769...   \n",
       "BUT-5         [4.563167174061512, 5.156884411054435, 1.38264...   \n",
       "POR-1         [0.8100384095577873, 10.038192931921522, 3.583...   \n",
       "BUT-4         [2.0490493554891245, 2.9026863518950847, 11.61...   \n",
       "SJB-1         [0.9351528875660051, 3.262832188011892, 2.4624...   \n",
       "BUT-3         [1.0148008159231676, 1.0511750429816773, 1.018...   \n",
       "BUT-2         [0.9567358980816547, 1.0531143014578779, 1.210...   \n",
       "TEJ-2         [0.7029273399467104, 1.3354256250764396, 0.986...   \n",
       "TEJ-1         [1.0865748407891955, 1.086761419952321, 1.1536...   \n",
       "SEF-1         [0.990386022399871, 0.957672654271169, 1.07976...   \n",
       "BUT-1         [0.8734683094459214, 0.9401437964593449, 0.707...   \n",
       "11-Escanilla  [1.45, 3.15, 2.65, 1.9, 1.75, 2.7, 2.05, 1.8, ...   \n",
       "12-Escanilla  [2.85, 1.75, 2.2, 2.2, 2.25, 2.0, 2.3, 2.55, 1...   \n",
       "10-Sobrarbe   [2.25, 3.2, 1.7, 2.5, 2.7, 2.15, 2.15, 1.95, 2...   \n",
       "\n",
       "                                                          76Age  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [-307.07890707133015, -0.8928101005134416, 17....   \n",
       "POR-3         [34.3248370021054, 83.01650526932218, 153.0324...   \n",
       "BUT-5         [515.4568924560183, -599.9301958570051, 170.06...   \n",
       "POR-1         [102.48489961586091, -183.0155274310181, 20.37...   \n",
       "BUT-4         [-108.47398511641335, -1075.494766231362, 590....   \n",
       "SJB-1         [42.02327500469606, 115.0647220463812, 226.466...   \n",
       "BUT-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SEF-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11-Escanilla  [310.0, 325.0, 336.0, 281.0, 410.0, 309.0, 262...   \n",
       "12-Escanilla  [345.0, 277.0, 409.0, 354.0, 330.0, 324.0, 326...   \n",
       "10-Sobrarbe   [373.0, 301.0, 282.0, 302.0, 326.0, 296.0, 300...   \n",
       "\n",
       "                                                      76Age_err  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [350.5904941293329, 396.0820325790396, 41.2019...   \n",
       "POR-3         [610.3829868966902, 402.33668293556605, 73.693...   \n",
       "BUT-5         [433.2945978448812, 812.5849145152981, 159.693...   \n",
       "POR-1         [243.56638391351234, 784.5500500306964, 289.45...   \n",
       "BUT-4         [136.07972415269364, 1441.1587890762612, 1163....   \n",
       "SJB-1         [194.43094236269678, 193.91190139527237, 346.0...   \n",
       "BUT-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SEF-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11-Escanilla  [14.5, 27.0, 18.5, 22.0, 26.0, 21.5, 22.5, 20....   \n",
       "12-Escanilla  [26.5, 20.0, 22.0, 21.0, 24.5, 27.0, 22.0, 29....   \n",
       "10-Sobrarbe   [47.5, 23.5, 21.5, 17.0, 29.0, 22.0, 19.0, 19....   \n",
       "\n",
       "                                                        BestAge  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [42.96919594561263, 46.708419534945264, 48.226...   \n",
       "POR-3         [45.13831407280074, 85.16718033964855, 86.8715...   \n",
       "BUT-5         [79.95714249032814, 80.70902156952796, 82.3027...   \n",
       "POR-1         [43.43500851336782, 81.55797905712907, 84.2409...   \n",
       "BUT-4         [85.97732321618626, 87.03706690423192, 87.1322...   \n",
       "SJB-1         [83.07271483667525, 86.83829603617806, 87.0112...   \n",
       "BUT-3         [67.11326049864458, 77.74625164294953, 79.4024...   \n",
       "BUT-2         [77.21743369794198, 81.39340264826086, 83.6042...   \n",
       "TEJ-2         [62.5294364021132, 70.12316161605732, 80.86974...   \n",
       "TEJ-1         [85.1407481711587, 85.19426504155912, 85.62006...   \n",
       "SEF-1         [79.78104362747698, 80.90398224501742, 83.4355...   \n",
       "BUT-1         [81.90928404046831, 82.51307664719889, 83.8042...   \n",
       "11-Escanilla  [282.8, 284.6, 285.9, 287.8, 289.0, 294.3, 294...   \n",
       "12-Escanilla  [297.1, 297.1, 298.0, 298.1, 305.6, 306.4, 307...   \n",
       "10-Sobrarbe   [283.4, 285.0, 286.5, 286.9, 289.4, 290.2, 291...   \n",
       "\n",
       "                                                 BestAge_err_sx  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [0.800852038337176, 0.6515547700251538, 0.9993...   \n",
       "POR-3         [6.8794994529228966, 3.1479894061072287, 1.769...   \n",
       "BUT-5         [4.563167174061512, 5.156884411054435, 1.38264...   \n",
       "POR-1         [0.8100384095577873, 10.038192931921522, 3.583...   \n",
       "BUT-4         [2.0490493554891245, 2.9026863518950847, 11.61...   \n",
       "SJB-1         [0.9351528875660051, 3.262832188011892, 2.4624...   \n",
       "BUT-3         [1.0148008159231676, 1.0511750429816773, 1.018...   \n",
       "BUT-2         [0.9567358980816547, 1.0531143014578779, 1.210...   \n",
       "TEJ-2         [0.7029273399467104, 1.3354256250764396, 0.986...   \n",
       "TEJ-1         [1.0865748407891955, 1.086761419952321, 1.1536...   \n",
       "SEF-1         [0.990386022399871, 0.957672654271169, 1.07976...   \n",
       "BUT-1         [0.8734683094459214, 0.9401437964593449, 0.707...   \n",
       "11-Escanilla  [1.45, 3.15, 2.65, 1.9, 1.75, 2.7, 2.05, 1.8, ...   \n",
       "12-Escanilla  [2.85, 1.75, 2.2, 2.2, 2.25, 2.0, 2.3, 2.55, 1...   \n",
       "10-Sobrarbe   [2.25, 3.2, 1.7, 2.5, 2.7, 2.15, 2.15, 1.95, 2...   \n",
       "\n",
       "                                             BestAge_err_stotal  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-5         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-4         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SJB-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SEF-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "12-Escanilla  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "10-Sobrarbe   [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "\n",
       "                                                          U_ppm  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-5         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-4         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SJB-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SEF-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11-Escanilla  [580.0, 941.0, 598.0, 186.9, 148.1, 191.8, 180...   \n",
       "12-Escanilla  [152.0, 340.0, 130.6, 360.0, 127.0, 166.0, 199...   \n",
       "10-Sobrarbe   [197.0, 697.0, 289.0, 701.0, 266.0, 319.0, 228...   \n",
       "\n",
       "                                                           U_Th  \\\n",
       "Sample_ID                                                         \n",
       "POR-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-5         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "POR-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-4         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SJB-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-3         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-2         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "TEJ-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "SEF-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "BUT-1         [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   \n",
       "11-Escanilla  [3.26, 33.2, 3.74, 1.28, 1.87, 1.62, 1.2, 1.34...   \n",
       "12-Escanilla  [1.94, 1.72, 1.11, 1.82, 1.39, 1.64, 1.9, 1.64...   \n",
       "10-Sobrarbe   [2.02, 1.83, 1.17, 2.29, 1.52, 1.79, 1.85, 1.4...   \n",
       "\n",
       "                                                           Th_U  \n",
       "Sample_ID                                                        \n",
       "POR-2         [0.627621449689062, 0.4961071900646707, 0.0520...  \n",
       "POR-3         [0.9837507073194807, 0.2970781234307026, 0.858...  \n",
       "BUT-5         [1.2867765283029227, 0.7227353978942941, 0.733...  \n",
       "POR-1         [2.5070011249322732, 0.6143287549109991, 0.361...  \n",
       "BUT-4         [0.5459033832726942, 0.8891614267348487, 0.793...  \n",
       "SJB-1         [0.704392609979317, 0.8704321658914768, 0.9760...  \n",
       "BUT-3         [0.32894736842105265, 0.3205128205128205, 0.45...  \n",
       "BUT-2         [0.18615040953090098, 0.29325513196480935, 0.2...  \n",
       "TEJ-2         [0.04642525533890437, 0.13175230566534915, 0.6...  \n",
       "TEJ-1         [0.40966816878328555, 0.2901915264074289, 0.73...  \n",
       "SEF-1         [0.28851702250432776, 0.5091649694501018, 0.42...  \n",
       "BUT-1         [0.40535062829347385, 0.46382189239332094, 0.2...  \n",
       "11-Escanilla  [0.3067484662576687, 0.03012048192771084, 0.26...  \n",
       "12-Escanilla  [0.5154639175257733, 0.5813953488372093, 0.900...  \n",
       "10-Sobrarbe   [0.49504950495049505, 0.5464480874316939, 0.85...  \n",
       "\n",
       "[15 rows x 21 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify file paths to data input file(s)\n",
    "dataToLoad = ['Data_Upload_1.xlsx',\n",
    "              'Data_Upload_2.xlsx']\n",
    "\n",
    "main_df, main_byid_df, samples_df, analyses_df = loadDataExcel(dataToLoad)\n",
    "main_byid_df.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Check That the Data Loaded Properly & Review Unique Samples\n",
    "\n",
    "Execute the following code to examine the frist 5 rows of your data to make sure it loaded correctly and to view the unique samples that were found in your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MDAFunc.check_data_loading(main_byid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following 32 unique samples were found in your data:\n",
      "\n",
      "['POR-2' 'POR-3' 'BUT-5' 'POR-1' 'BUT-4' 'SJB-1' 'BUT-3' 'BUT-2' 'TEJ-2'\n",
      " 'TEJ-1' 'SEF-1' 'BUT-1' '11-Escanilla' '12-Escanilla' '10-Sobrarbe'\n",
      " '7-Guaso' '13-Guaso' '5-Morillo' '6-Morillo' '14AB-M02' '14AB-A04'\n",
      " '14AB-A05' '4-Ainsa' '14AB-A06' '15AB-352' '15AB-118' '15AB-150'\n",
      " '3-Gerbe' '14AB-G07' '2-Arro' '1-Fosado' '14AB-F01']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'Sample_ID' is both an index level and a column label, which is ambiguous.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-fedae1487ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mcheck_data_loading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain_byid_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-51-fedae1487ca3>\u001b[0m in \u001b[0;36mcheck_data_loading\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0msample_amounts_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     sample_amounts_table.rename(columns={\n\u001b[1;32m     10\u001b[0m     'Age': 'Sample_Size'},\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed)\u001b[0m\n\u001b[1;32m   5799\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5801\u001b[0;31m         return groupby_generic.DataFrameGroupBy(\n\u001b[0m\u001b[1;32m   5802\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5803\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated)\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_grouper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/grouper.py\u001b[0m in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate)\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m                     \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m                 \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_check_label_or_level_ambiguity\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1645\u001b[0m                 \u001b[0;34mf\"{label_article} {label_type} label, which is ambiguous.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m             )\n\u001b[0;32m-> 1647\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'Sample_ID' is both an index level and a column label, which is ambiguous."
     ]
    }
   ],
   "source": [
    "\n",
    "def check_data_loading(df):\n",
    "    amount_of_samples = df.Sample_ID.nunique()\n",
    "    print(\"The following \" + str(amount_of_samples) + \" unique samples were found in your data:\")\n",
    "    print(\"\")\n",
    "    sample_array = df[\"Sample_ID\"].unique() \n",
    "    print(sample_array)\n",
    "    \n",
    "    sample_amounts_table = df.groupby('Sample_ID').Age.nunique().reset_index()\n",
    "    sample_amounts_table.rename(columns={\n",
    "    'Age': 'Sample_Size'},\n",
    "    inplace=True)\n",
    "    print('')\n",
    "    print('Summary of sample size disitrbution in the dataset:')\n",
    "    print('')\n",
    "    print(sample_amounts_table)\n",
    "    return \n",
    "\n",
    "check_data_loading(main_byid_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select Samples and Error \n",
    "Individual or groups of samples can be selected by entering their unique Sample ID's in an array or tuple (see example below for the correct syntax). This sample list will be used for all subsequent plotting and analysis functions. \n",
    "\n",
    "Also select the uncertainty as 1sigma or 2sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['GB3','GabGBm','VanLion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sample_ID   Age  Error  Age_Plus_Error  Age_Minus_Error  age_div_sigma_2  \\\n",
      "0          GB3  60.4    3.5            63.9             56.9         4.930612   \n",
      "1          GB3  61.5    2.7            64.2             58.8         8.436214   \n",
      "2          GB3  63.1    2.7            65.8             60.4         8.655693   \n",
      "3          GB3  63.9    3.3            67.2             60.6         5.867769   \n",
      "4          GB3  64.3    3.0            67.3             61.3         7.144444   \n",
      "...        ...   ...    ...             ...              ...              ...   \n",
      "1074   VanLion   NaN    NaN             NaN              NaN              NaN   \n",
      "1075   VanLion   NaN    NaN             NaN              NaN              NaN   \n",
      "1076   VanLion   NaN    NaN             NaN              NaN              NaN   \n",
      "1077   VanLion   NaN    NaN             NaN              NaN              NaN   \n",
      "1078   VanLion   NaN    NaN             NaN              NaN              NaN   \n",
      "\n",
      "      one_div_sigma_2  \n",
      "0            0.081633  \n",
      "1            0.137174  \n",
      "2            0.137174  \n",
      "3            0.091827  \n",
      "4            0.111111  \n",
      "...               ...  \n",
      "1074              NaN  \n",
      "1075              NaN  \n",
      "1076              NaN  \n",
      "1077              NaN  \n",
      "1078              NaN  \n",
      "\n",
      "[1079 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "#Add a Column to Add/Subtract Error and age/sigma^2 and 1/sigma^2 for Mean Weighted Calculations\n",
    "def add_sub_error_column():\n",
    "    df['Age_Plus_Error']= df.Age + df.Error\n",
    "    df['Age_Minus_Error']= df.Age - df.Error \n",
    "    df['age_div_sigma_2'] = df.Age/((df.Error)**2)\n",
    "    df['one_div_sigma_2'] = 1/(df.Error**2)\n",
    "add_sub_error_column()\n",
    "\n",
    "#Drop all na values\n",
    "def dropna():\n",
    "      df.dropna(how = 'all')\n",
    "dropna()    \n",
    "    \n",
    "#Create a new datasets with only the selected samples: \n",
    "\n",
    "main_df = df[df['Sample_ID'].isin(sample_list)] \n",
    "main_df_id_index = main_df.copy()\n",
    "main_df_id_index.set_index('Sample_ID', inplace=True,drop=False)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleToData(sample_list, main_byid_df, sampleLabel='Sample_ID', bestAge='BestAge', bestAgeErr='BestAge_err_sx', sigma='1sigma'):\n",
    "    \"\"\"\n",
    "    Returns arrays of single grain ages, 1 sigma errors, the number of analyses, and labels for\n",
    "    individual samples or groups of samples\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sampleList : array of sample IDs\n",
    "        Must be in form for individual samples: ['Sample1', 'Sample2', . . . , etc.]\n",
    "        Must be in the form for groups of samples: [(['Sample1','Sample2', . . . , etc.], 'Group 1 name'),\n",
    "                                                    (['Sample1','Sample2', . . . , etc.], 'Group 2 name')]\n",
    "    main_byid_df : DZ database, output from loadData()\n",
    "    sampleLabel : (optional) The name of the column that contains the desired sample label. Default is 'Sample_ID'\n",
    "    bestAge : (optional) The name of the column that contains the 'Best U-Pb Age' of the analysis. Default is 'BestAge'\n",
    "    bestAgeErr : (optional) The name of the column that contains the 'Best U-Pb Age' uncertainty of the analysis. Default is 'BestAge_err'\n",
    "    sigma : (optional) Specify whether bestAgeErr are 1-sigma or 2-sigma errors. Default is '1sigma', but '2sigma' can also be specified.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ages : array of ages for each sample or sample group\n",
    "    errors : array of 1 sigma errors for each sample or sample group\n",
    "    numGrains : array of numbers of analyses within each sample or sample group\n",
    "    labels : array of labels for samples or sample groups\n",
    "    Notes\n",
    "    -----\n",
    "    \"\"\"\n",
    "    N = len(sample_list)\n",
    "    ages = []    \n",
    "    errors = []\n",
    "    numGrains = []\n",
    "    labels = []\n",
    "\n",
    "    if type(sample_list[0])==tuple:\n",
    "        for i in range(N):\n",
    "            samples = sample_list[i][0]\n",
    "            # Verify that all samples are in the database\n",
    "            if not all(sample in list(main_byid_df.Sample_ID) for sample in sample_list[i][0]):\n",
    "                print('These samples are not in the database - check for typos!')\n",
    "                print(list(np.setdiff1d(sample_list[i][0],list(main_byid_df.Sample_ID))))\n",
    "                print('Function stopped')\n",
    "                break\n",
    "            sampleAges = []\n",
    "            sampleErrors = []\n",
    "            for sample in samples:                             \n",
    "                sampleAges = np.append(sampleAges, main_byid_df.loc[sample, bestAge])\n",
    "                if sigma == '2sigma':\n",
    "                    sampleErrors = np.append(sampleErrors, main_byid_df.loc[sample, bestAgeErr]/2)\n",
    "                else:\n",
    "                    sampleErrors = np.append(sampleErrors, main_byid_df.loc[sample, bestAgeErr])                \n",
    "            ages.append(sampleAges)\n",
    "            errors.append(sampleErrors)\n",
    "            numGrains.append(len(sampleAges))\n",
    "            labels.append(sample_list[i][1])\n",
    "    else:\n",
    "        for sample in sample_list:\n",
    "            # Verify that all samples are in the database\n",
    "            if not all(sample in list(main_byid_df.Sample_ID) for sample in sample_list):\n",
    "                print('These samples are not in the database - check for typos!')\n",
    "                print(list(np.setdiff1d(sample_list,list(main_byid_df.Sample_ID))))\n",
    "                print('Function stopped')\n",
    "                break            \n",
    "            ages.append(main_byid_df.loc[sample, bestAge])\n",
    "            if sigma == '2sigma':\n",
    "                errors.append(main_byid_df.loc[sample, bestAgeErr]/2.)\n",
    "            else:\n",
    "                errors.append(main_byid_df.loc[sample, bestAgeErr])\n",
    "            numGrains.append(len(main_byid_df.loc[sample, bestAge]))\n",
    "            labels.append(main_byid_df.loc[sample,sampleLabel])\n",
    "    return ages, errors, numGrains, labels\n",
    " \n",
    "\n",
    "def sampleToVariable(sample_list, main_byid_df, variableName):\n",
    "    \"\"\"\n",
    "    Returns arrays of a grain variable (e.g., U_ppm) for\n",
    "    an array of sample IDs or a tuple of sample IDs and group name\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sampleList : array of sample IDs\n",
    "        Must be in form for individual samples: ['Sample1', 'Sample2', . . . , etc.]\n",
    "        Must be in the form for groups of samples: [(['Sample1','Sample2', . . . , etc.], 'Group 1 name'),\n",
    "                                                    (['Sample1','Sample2', . . . , etc.], 'Group 2 name')]\n",
    "    main_byid_df : Detrital database. Output from loadData()\n",
    "    variableName : Column name of the desired variable\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    variable : array of specified variable for each sample or sample group\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    \"\"\"\n",
    "    N = len(sample_list)\n",
    "    variable = []\n",
    "    if type(sample_list[0])==tuple:\n",
    "        for i in range(N):\n",
    "            samples = sample_list[i][0]\n",
    "            sampleVariables = []\n",
    "            for sample in samples:\n",
    "                sampleVariables = np.append(sampleVariables, main_byid_df.loc[sample, variableName])\n",
    "            variable.append(sampleVariables)\n",
    "    else:\n",
    "        for sample in sample_list:\n",
    "            variable.append(main_byid_df.loc[sample, variableName])\n",
    "\n",
    "    return variable  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ages, errors, numGrains, labels = sampleToData(sample_list,  main_byid_df, sigma = '1sigma');\n",
    "\n",
    "def find_youngest_cluster(data_err, min_cluster_size):\n",
    "    \"\"\"\n",
    "    Finds the youngest cluster of analyses that overlap \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_err : array of tuples [(age1, error1), (age2, error2), etc.]\n",
    "\n",
    "    \"\"\"\n",
    "    i_min = 0\n",
    "    i_max = 0\n",
    "    for i in range(1, len(data_err)):\n",
    "        top = data_err[i_min][0] + data_err[i_min][1]\n",
    "        bottom = data_err[i][0] - data_err[i][1]\n",
    "        if (top >= bottom):\n",
    "            i_max = i\n",
    "        elif i_max - i_min + 1 >= min_cluster_size:\n",
    "            break\n",
    "        else:\n",
    "            i_min = i\n",
    "            i_max = i\n",
    "    return data_err[i_min: i_max + 1] if i_min < i_max else [], i_max\n",
    "\n",
    "def weightedMean(ages,error1s,conf=0.95):\n",
    "    \"\"\"\n",
    "    Calculates the weighted mean, its 2-sigma uncertainty, and MSWD\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    ages : a 1D array of ages\n",
    "    errors : an array of 1-sigma errors\n",
    "    conf : (optional) confidence level\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Twm : weighted mean age\n",
    "    sm : 2-sigma uncertainty\n",
    "    MSWD : Mean Square of the Weighted Deviation\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    from scipy import stats\n",
    "    \n",
    "    w=np.array(error1s)**(-2)/np.sum(np.array(error1s)**(-2)) # weight\n",
    "    Twm=np.sum(w*np.array(ages)) # weight mean of age\n",
    "    S=np.sum((np.array(ages)-Twm)**2/np.array(error1s)**2) # S\n",
    "    N=len(ages)\n",
    "    MSWD=S/(N-1) # Mean Square of the Weighted Deviation\n",
    "    # Standard deviation of the weighted mean (2 sigma)\n",
    "    sm=stats.norm.ppf(conf+(1-conf)/2.)*np.sqrt(1./np.sum(np.array(error1s)**(-2)))\n",
    "    \n",
    "    return(Twm,sm,MSWD)\n",
    "\n",
    "def PDPcalcAges(ages, errors, x1=0, x2=4500, xdif=1, cumulative=False):    \n",
    "    \"\"\"\n",
    "    Computes the PDP for an array of ages.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    ages : array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : array of 1s errors\n",
    "    x1 : (optional) beginning of range to compute PDP (default = 0 Ma)\n",
    "    x2 : (optional) end of range to compute PDP (default = 4500 Ma)\n",
    "    xdif : (optional) bin size to compute PDP (default = 1 Ma)\n",
    "    cumulative : (optional) If True, will compute a cumulative PDP (CPDP)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    PDP_age : array of ages that PDP is computed over    \n",
    "    PDP : array of PDP functions\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    \"\"\"\n",
    "    from scipy.stats import norm\n",
    "    PDP_age = np.arange(0, 4500+xdif, xdif) # Ensures that the PDP is calculated over all of geologic time\n",
    "    PDPe = np.empty(shape=(len(ages),len(PDP_age))) # Create an empty array of appropriate shape\n",
    "    PDP = np.zeros_like(PDPe) # Copy the array, but with zeros\n",
    "    for i in range(len(ages)):\n",
    "        data = ages[i]\n",
    "        data_err = errors[i]\n",
    "        pdf_cum = 0 # Creates an empty variable        \n",
    "        for j in range(len(data)):      \n",
    "            age = data[j]\n",
    "            error = data_err[j]\n",
    "            pdf = norm.pdf(PDP_age, age, error)\n",
    "            pdf_cum = pdf_cum + pdf \n",
    "        pdf_cum = np.around(pdf_cum/np.trapz(pdf_cum), decimals=10)\n",
    "        if cumulative:\n",
    "            pdf_cum = np.cumsum(pdf_cum)        \n",
    "        PDP[i] = pdf_cum\n",
    "    PDP_age = PDP_age[int(x1/xdif):int((x2+xdif)/xdif)] # Only select the values within the specified plotting age range\n",
    "    PDPportionRange = np.arange(x1, x2+xdif, xdif)\n",
    "    PDPportionEmpty = np.empty(shape=(len(ages),len(PDPportionRange)))\n",
    "    PDPportion = np.zeros_like(PDPportionEmpty) # Copy the array, but with zeros\n",
    "    for i in range(len(ages)):\n",
    "        PDPportion[i] = PDP[i][int(x1/xdif):int((x2+xdif)/xdif)] # Only select the values within the specified plotting age range\n",
    "    return PDP_age, PDPportion\n",
    "\n",
    "\n",
    "def peakAge(DF_age, DF, ages, errors, thres=0.05, minDist=5, minPeakSize=3):\n",
    "    \"\"\"\n",
    "    Identifies peak ages in a given relative probability distribution (e.g., PDP, KDE)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DF_age, DF : Arrays of ages and probability values of a relative probability distribution (e.g., PDP, KDE)\n",
    "    thres : Threshold of what constitues a peak (from 0 to 1). Default = 0.05\n",
    "    minDist : Minimum distance (Myr) between adjacent peaks. Default = 5\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    peakAges : array of peak ages (Myr) for each sample or sample group\n",
    "    indexes : array of the indexes where peak ages occur\n",
    "    \n",
    "    Notes\n",
    "    -----\n",
    "    Requires the package peakutils to be installed\n",
    "    pip install peakutils\n",
    "    \"\"\"     \n",
    "    import peakutils\n",
    "    peakAges = []\n",
    "    indexes = []\n",
    "    for i in range(len(DF)):\n",
    "        indexes = indexes + [list(peakutils.indexes(DF[i], thres=thres, min_dist=minDist))]\n",
    "        peakAges = peakAges + [list(DF_age[indexes[i]])]\n",
    "    peakAgeGrain = peakAgesGrains(peakAges, ages, errors)\n",
    "    \n",
    "    # Remove peaks with fewer grains than the minimum peak size\n",
    "    for i in reversed(range(len(peakAges))):\n",
    "        for j in reversed(range(len(peakAgeGrain[i]))):\n",
    "            if peakAgeGrain[i][j] < minPeakSize:\n",
    "                del peakAges[i][j]\n",
    "                del peakAgeGrain[i][j]\n",
    "                del indexes[i][j]\n",
    "    return peakAges, indexes, peakAgeGrain\n",
    "\n",
    "def peakAgesGrains(peakAges, ages, errors, sigma=2):\n",
    "    import copy\n",
    "    peakAgeGrain = copy.deepcopy(peakAges)\n",
    "    for i in range(len(peakAges)): # One loop per sample or sample group\n",
    "        for j in range(len(peakAges[i])): # One loop per peak\n",
    "            c = 0 # counter variable\n",
    "            for k in range(len(ages[i])): # Loop through each analysis\n",
    "                if (ages[i][k]-errors[i][k]*sigma <= peakAges[i][j] <= ages[i][k]+errors[i][k]*sigma):\n",
    "                    c = c+1\n",
    "            peakAgeGrain[i][j] = c\n",
    "    return peakAgeGrain   \n",
    "\n",
    "def exportPeakAge(labels, peakAges, peakAgesGrains, fileName='peakAges.csv'):\n",
    "    import csv\n",
    "    with open(fileName, 'w', newline='') as f: #Select the CSV file to save data to\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow((['Peak Age']))\n",
    "        writer.writerow((''))\n",
    "        for i in range(len(peakAges)):\n",
    "            writer.writerow(([labels[i]]))\n",
    "            writer.writerow((peakAges[i][j]) for j in range(len(peakAges[i])))\n",
    "            writer.writerow((peakAgesGrains[i][j]) for j in range(len(peakAgesGrains[i])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MDA Calculators: 1-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. YSG: Youngest Single Grain \n",
    "As outlined in Dickinson and Gehrels (2009b) the youngest single grain (YSG) method uses the date and uncertainty (Sx) of the youngest grain measured within the sample as the MDA. If the youngest date has a 1s uncertainty >10 M.y. and overlaps with the second-youngest date, then the later can be substituted for greater precision (Dickinson and Gehrels, 2009b). The uncertainty of the youngest grain is used as the uncertainty of the MDA (Dickinson and Gehrels, 2009b).\n",
    "\n",
    "D&G 2009: \n",
    "YSG: youngest single DZ grain age with 1Ïƒ uncertainty from a table of Uâ€“Pb grain ages, except that where 1Ïƒ > 10 Ma for the youngest single grain age and that grain age overlaps at 1Ïƒ with the next youngest grain age, the latter grain age is substituted for greater precision. YSG is a measure of youngest possible DZ age, but inherent lack of reproducibility diminishes confidence in its reliability because some individual YSG ages might be spurious due to lead loss. Youngest grain DOES not include added uncertainty as Sharman does\n",
    "\n",
    "Sharman 2020:\n",
    "The YSG is calculated by sorting each age plus 2Ïƒ uncertainty and selecting the first analysis in this list. As defined this way, an older, more precise analysis may be selected instead of a younger, less precise analysis. For example, if two young grains are present with measured UePb dates of 100 Â± 4 Ma and 101 Â± 2 Ma, the later analysis would be selected as the YSG. This approach follows Sharman et al. (2018) with the exception of using 2Ïƒ uncertainty instead of 1Ïƒ uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[60.4, 3.5], [65.9, 3.0], [81.9, 5.5]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def YSG(ages, errors, sigma=1):\n",
    "    \"\"\"\n",
    "    Calculate the youngest single grain (YSG), where the YSG is defined as the youngest grain age plus error of uncertainty sigma (default is 2 sigma).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    sigma : (optional) Options are 1 or 2 (default is 2)\n",
    "=\n",
    "    Returns\n",
    "    -------\n",
    "    YSG : a list of [youngest single grain (Ma), 2-sigma error of the youngest single grain (Ma)] such that len(YSG) = len(ages)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    YSG = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "        if sigma == 1: \n",
    "            data_err1s = list(zip(ages[i], errors[i]))\n",
    "            data_err1s.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 1s error\n",
    "            YSG.append([data_err1s[0][0],data_err1s[0][1]]) # Reporting 1-sigma error\n",
    "        if sigma == 2:\n",
    "            data_err2s = list(zip(ages[i], errors[i]*2))\n",
    "            data_err2s.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 2s error\n",
    "            YSG.append([data_err2s[0][0],data_err2s[0][1]]) # Reporting 2-sigma error\n",
    "\n",
    "    return YSG\n",
    "\n",
    "YSG(ages, errors, sigma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          YSG  Error\n",
      "GB3      60.4    3.5\n",
      "GabGBm   65.9    3.0\n",
      "VanLion  81.9    5.5\n"
     ]
    }
   ],
   "source": [
    "YSG = YSG(ages, errors)\n",
    "YSG_Table = pd.DataFrame(data=YSG, index=[sample_list], columns=['YSG', 'Error'])\n",
    "print(YSG_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. YPP: Youngest Graphical Peak \n",
    "The youngest graphical peak (YPP) method of Dickinson and Gehrels (2009b) is calculated from the age of the youngest mode in the probability density plot (PDP) of the measured sample population that is composed of two or more grains. This is interpreted to be the youngest reproducible peak. There is no uncertainty associated with a MDA calculated by this method (Dickinson and Gehrels, 2009b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def YPP(ages, errors, min_cluster_size=2, thres=0.01, minDist=1, xdif=0.1):\n",
    "    \"\"\"\n",
    "    Calculates the youngest graphical peak (after Dickinson and Gehrels (2009): EPSL) that has at least min_cluster_size analyses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    min_cluster_size : (optional) the minimum number of analyses that fall within error of the youngest graphical peak (default = 2)\n",
    "    thres : (optional) threshold of what constitues a peak (from 0 to 1). Default = 0.01\n",
    "    minDist : (optional) minimum distance (Myr) between adjacent peaks. Default = 1\n",
    "    xdif : (optional) bin size to compute PDP (default = 0.1 Ma)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    YPP : [the age of the youngest graphical peak, rounded to the nearest 0.1 Ma]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    import peakutils\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    # Calculate the PDP - note that a small xdif may be desired for increased precision\n",
    "    PDP_age, PDP = PDPcalcAges(ages, errors, xdif=xdif)\n",
    "  \n",
    "\n",
    "    YPP = []\n",
    "    for i in range(len(ages)):\n",
    "\n",
    "        # Calculate peak indexes\n",
    "        indexes = list(peakutils.indexes(PDP[i], thres=thres, min_dist=minDist))\n",
    "        # Peak ages\n",
    "        peakAges = PDP_age[indexes]\n",
    "        # Number of grains per peak\n",
    "        peakAgeGrain = peakAgesGrains([peakAges], [ages[i]], [errors[i]])[0]\n",
    "        # Zip peak ages and grains per peak\n",
    "        peakAgesGrains_ = list(zip(peakAges, peakAgeGrain))\n",
    "        # Filter out peaks with less than min_cluster_size grains\n",
    "        peakAgesGrainsFiltered = list(filter(lambda x: x[1] >= min_cluster_size, peakAgesGrains_))\n",
    "\n",
    "        # Check if a YPP was found, and if not return NaN\n",
    "        if len(peakAgesGrainsFiltered) > 0:\n",
    "            YPP.append(np.round(np.min([x[0] for x in peakAgesGrainsFiltered]),1))\n",
    "        else:\n",
    "            YPP.append(np.nan)\n",
    "\n",
    "    return YPP\n",
    "\n",
    "YPP(ages, errors, min_cluster_size=2, thres=0.01, minDist=1, xdif=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         WM\n",
      "GB3     NaN\n",
      "GabGBm  NaN\n",
      "VanLion NaN\n"
     ]
    }
   ],
   "source": [
    "YPP = YPP(ages, errors)\n",
    "YPP_Table = pd.DataFrame(data=YPP, index=[sample_list], columns=['WM'])\n",
    "print(YPP_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. YGC 1s: Youngest Grain Cluster at 1s\n",
    "The youngest grain cluster at 1s uncertainty (YGC 1s) is calculated by computing the weighted average, weighted by date uncertainty, of the youngest two or more dates that overlap within uncertainty at 1s (Dickinson and Gehrels, 2009b). The uncertainty of the calculated MDA is the uncertainty of the weighted average age (Dickinson and Gehrels, 2009b). Although not specified in Dickinson and Gehrels (2009b), the overlapping sub-sample should be limited by the youngest upper limit of uncertainty, which may or may not be associated with the youngest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[64.23097838867837, 1.9515812916628867, 0.46670651778652, 10],\n",
       " [68.59109508363993, 1.0340023653457941, 0.27946762622286236, 42],\n",
       " [86.75221551232589, 3.681311202552228, 0.1948118155322165, 9]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def YC1s(ages, errors, min_cluster_size=2):\n",
    "    \"\"\"\n",
    "    Calculate the youngest grain cluster that overlaps at 1-sigma error (see Dickinson and Gehrels (2009): Earth and Planetary Science Letters and Sharman et al. (2018): The Depositional Record for an explanation).\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    min_cluster_size : (optional) minimum number of grains in the cluster (default = 2)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    YC1s : a list of [the weighted mean age of the youngest cluster, the 2-sigma uncertainty of the weighted mean age of the youngest cluster, the MSWD of the youngest cluster, the number of analyses in the youngest cluster] such that len(YC1s) = len(ages)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    YC1s = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "\n",
    "        data_err1s = list(zip(ages[i], errors[i]))\n",
    "        data_err1s_ageSort = list(zip(ages[i], errors[i]))\n",
    "        data_err1s_ageSort.sort(key=lambda d: d[0]) # Sort based on age\n",
    "        data_err1s.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 1s error\n",
    "\n",
    "\n",
    "        YC1s_cluster, YC1s_imax = find_youngest_cluster(data_err1s, min_cluster_size)\n",
    "        YC1s_WM = weightedMean(np.array([d[0] for d in YC1s_cluster]), np.array([d[1] for d in YC1s_cluster]))\n",
    "\n",
    "        # Return NaN if YC1s did not find a cluster\n",
    "        if YC1s_WM[0] == 0.0:\n",
    "            YC1s.append([np.nan,np.nan,np.nan,np.nan])\n",
    "        else:\n",
    "            YC1s.append([YC1s_WM[0], YC1s_WM[1], YC1s_WM[2], len(YC1s_cluster)])\n",
    "\n",
    "    return YC1s\n",
    "\n",
    "YC1s(ages, errors, min_cluster_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                WM     Error      MSWD  Grains\n",
      "GB3      64.230978  1.951581  0.466707      10\n",
      "GabGBm   68.591095  1.034002  0.279468      42\n",
      "VanLion  86.752216  3.681311  0.194812       9\n"
     ]
    }
   ],
   "source": [
    "YC1s = YC1s(ages, errors)\n",
    "YC1s_Table = pd.DataFrame(data=YC1s, index=[sample_list], columns=['WM', 'Error', 'MSWD', 'Grains'])\n",
    "print(YC1s_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. YGC 2s: Youngest Grain Cluster at 2s \n",
    "The youngest grain cluster at 2s uncertainty (YGC 2s) is calculated by computing the weighted average, weighted by date uncertainty, of the youngest three or more dates that overlap within uncertainty at 2s (Dickinson and Gehrels, 2009b). The uncertainty of the calculated MDA is the uncertainty of the weighted average age (Dickinson and Gehrels, 2009b). As per YGC 1s, the sub-sample should be limited by the youngest upper limit of uncertainty, which may or may not be associated with the youngest date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[66.21107319307218, 0.7440379234840364, 0.7363983260390683, 20],\n",
       " [70.74185585107942, 0.3960299612162146, 0.7938769309479833, 78],\n",
       " [94.32271472227144, 0.4567112510177758, 0.4042925581463038, 86]]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def YC2s(ages, errors, min_cluster_size=3):\n",
    "    \"\"\"\n",
    "    Calculate the youngest grain cluster that overlaps at 2-sigma error (see Dickinson and Gehrels (2009): Earth and Planetary Science Letters and Sharman et al. (2018): The Depositional Record for an explanation).\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    min_cluster_size : (optional) minimum number of grains in the cluster (default = 3)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    YC2s : [the weighted mean age of the youngest cluster, the 1-sigma uncertainty of the weighted mean age of the youngest cluster, the MSWD of the youngest cluster, the number of analyses in the youngest cluster] such that len(YC2s) = len(ages)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    YC2s = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "\n",
    "        data_err2s = list(zip(ages[i], errors[i]*2))\n",
    "        data_err2s_ageSort = list(zip(ages[i], errors[i]*2))\n",
    "        data_err2s_ageSort.sort(key=lambda d: d[0]) # Sort based on age\n",
    "        data_err2s.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 2s error\n",
    "\n",
    "        YC2s_cluster, YC2s_imax = find_youngest_cluster(data_err2s, min_cluster_size)\n",
    "        YC2s_WM = weightedMean(np.array([d[0] for d in YC2s_cluster]), np.array([d[1] for d in YC2s_cluster])/2)\n",
    "\n",
    "        # Return NaN if YC2s did not find a cluster\n",
    "        if YC2s_WM[0] == 0.0:\n",
    "            YC2s.append([np.nan,np.nan,np.nan,np.nan])\n",
    "        else:\n",
    "            YC2s.append([YC2s_WM[0], YC2s_WM[1]/2, YC2s_WM[2], len(YC2s_cluster)])\n",
    "\n",
    "    return YC2s\n",
    "\n",
    "YC2s(ages, errors, min_cluster_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                WM     Error      MSWD  Grains\n",
      "GB3      66.211073  0.744038  0.736398      20\n",
      "GabGBm   70.741856  0.396030  0.793877      78\n",
      "VanLion  94.322715  0.456711  0.404293      86\n"
     ]
    }
   ],
   "source": [
    "YC2s = YC2s(ages, errors)\n",
    "YC2s_Table = pd.DataFrame(data=YC2s, index=[sample_list], columns=['WM', 'Error', 'MSWD', 'Grains'])\n",
    "print(YC2s_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. YDZ: Youngest Detrital Zircon \n",
    "The youngest detrital zircon (YDZ) method (Dickinson and Gehrels, 2009b) uses an algorithm in Isoplot (Ludwig, 2012) that performs a Monte Carlo approach to determine a MDA and uncertainty given a user-selected sub-sam- ple of dates. In each simulation, the input dates are adjusted to be younger or older by a randomly chosen amount of their uncer- tainty. The youngest resulting date is recorded and the process is repeated for w10,000 simulations (Ludwig, 2012). The mode of the resulting distribution is used as the MDA and the asymmetric dis- tribution is taken as the uncertainty (Dickinson and Gehrels, 2009b). Dates within 5s uncertainty bound of the youngest grain should be included in the calculation to ensure that all dates that may influence the final age produced by the YDZ algorithm are considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-c17fde4cadd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mYDZ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mYDZ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchartOutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-47-c17fde4cadd8>\u001b[0m in \u001b[0;36mYDZ\u001b[0;34m(ages, errors, iterations, chartOutput, bins)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Identify the youngest analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mYSG_age\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYSG_err1s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYSG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mageCutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYSG_age\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mYSG_err1s\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;31m# 5 for 5-sigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "def YDZ(ages, errors, iterations=10000, chartOutput = False, bins=25):\n",
    "    from scipy import stats\n",
    "    \"\"\"\"\n",
    "\n",
    "    NOTE: I Have not been able to reproduce Isoplot YDZ results using this adaptation - see Appendix B of Sharman and Malkowski (Earth-Science Reviews)\n",
    "\n",
    "    Calculate the youngest detrital zircon age based on the Monte Carlo approach of IsoPlot (Ludwig, 2012). The youngest analyses (i.e., within 5 sigma of the youngest analysis) are repeatedly resampled by a probability distribution defined by their age and uncertainty.\n",
    "    \n",
    "    The YDZ is defined as the mode of the resulting distribution of ages and the uncertainty is reported as the P2.5 and P97.5. The resulting range accounts for 95% of the total range in values.\n",
    "    Note that the age mode is defined as the midpoint of the histogram bin with the highest value (following IsoPlot). The mode is thus not independent of the choice of how many bins to define.\n",
    "    \n",
    "    Paramters\n",
    "    ---------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    iterations : (optional) the number of Monte Carlo iterations performed (default = 10000)\n",
    "    chartOutput : (optional) returns a figure showing the montecarlo distribution\n",
    "    bins : (optional) the number of bins to use in the histogram\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    YDZ : [the mode of youngest ages, the positive error (2-sigma), and the negative error (2-sigma)] Note that the error distribution is not symmetrical because it is based on the P2.5 and P97.5 of the distribution\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    YDZ = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "\n",
    "        data_err1s = list(zip(ages[i], errors[i]))\n",
    "        \n",
    "        # Identify the youngest analysis\n",
    "        YSG_age, YSG_err1s = YSG(ages[i], errors[i])[0]\n",
    "\n",
    "        ageCutoff = YSG_age + YSG_err1s*5 # 5 for 5-sigma\n",
    "\n",
    "        # Identify all analyses within 5 sigma of the youngest analysis\n",
    "        data_err1s.sort(key=lambda d: d[0]) # Sort based on age\n",
    "        filtered = list(filter(lambda x: x[0] < ageCutoff, data_err1s)) # Filter out ages too old\n",
    "\n",
    "        minAges = []\n",
    "        for i in range(iterations):\n",
    "            newAge_Ma = []\n",
    "            for analysis in filtered:\n",
    "                newAge_Ma.append(np.random.normal(loc = analysis[0], scale=analysis[1]))\n",
    "            minAges.append(min(newAge_Ma))\n",
    "    \n",
    "        # Find the mode of the minimum ages\n",
    "        binIndex, binAge = np.histogram(minAges, bins=bins)\n",
    "        binMaxIndex = np.argmax(binIndex)\n",
    "        binMaxAge = binAge[binMaxIndex]\n",
    "        mode = binMaxAge + (binAge[binMaxIndex+1] - binMaxAge)/2\n",
    "\n",
    "        YDZ.append([mode, np.percentile(minAges, 97.5)-mode, mode-np.percentile(minAges, 2.5)])\n",
    "\n",
    "        if chartOutput:\n",
    "            #KDE_age, KDE = dFunc.KDEcalcAges_2([minAges], bw=1, xdif=0.1)\n",
    "            fig, ax = plt.subplots(1)\n",
    "            ax.set_xlim(int(min(minAges))-1,int(max(minAges))+1,0.5)\n",
    "            #ax.plot(KDE_age, KDE[0])\n",
    "            ax.hist(minAges, bins=bins)\n",
    "            ax.axvline(mode,color='black')\n",
    "            ax.axvline(np.percentile(minAges,2.5),linestyle='--',color='black')\n",
    "            ax.axvline(np.percentile(minAges,97.5),linestyle='--',color='black')\n",
    "            ax.set_xlabel('Age (Ma)')\n",
    "\n",
    "    return YDZ\n",
    "\n",
    "YDZ(ages, errors, iterations=10000, chartOutput = False, bins=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WM     +Error     -Error\n",
      "POR-1  43.290553   1.758568   1.406285\n",
      "POR-2  42.868906   1.665905   1.456294\n",
      "POR-3  45.953479  12.717865  14.286115\n"
     ]
    }
   ],
   "source": [
    "YDZ1 = YDZ(ages, errors)\n",
    "YDZ_Table = pd.DataFrame(data=YDZ1, index=[sample_list], columns=['WM', '+Error', '-Error'])\n",
    "print(YDZ_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Y3Zo: Youngest Three Zircons (Y3Zo) \n",
    "Calculating a MDA from the weighted average of the youngest three zircons is achieved by the weighted average of the youngest three zircon dates that overlap within uncertainty (generally 2s) (e.g., Ross et al., 2017). The selection of three dates used in the Y3Zo should follow the same criteria as the YGC 2s method, however only the youngest three overlapping dates should be averaged. The uncertainty of the MDA calculated by these methods is the uncertainty of the weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[88.55868674128902, 1.7307221861612558, 1.0641801777570867],\n",
       " [49.02852625327225, 0.6549617484055197, 0.3634332771164162],\n",
       " [87.1963651168254, 2.1073847250928646, 0.33159156447922056]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Y3Zo(ages, errors, sigma=2):\n",
    "    \"\"\"\n",
    "    Calculates the weighted mean average of the youngest three zircons that overlap within uncertainty of sigma (default is 2-sigma) (see discussion in Coutts et al. (2019): Geoscience Frontiers)\n",
    "\n",
    "    Parameters\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    sigma : (optional) level of uncertainty to evaluate overlap (default is 2-sigma)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y3Zo : [the weighted mean age, the 2-sigma uncertainty, and the MSWD]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    Y3Zo = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "\n",
    "        if sigma == 1:\n",
    "            data_err = list(zip(ages[i], errors[i]))\n",
    "            data_err.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 1s error     \n",
    "        if sigma == 2:\n",
    "            data_err = list(zip(ages[i], errors[i]*2))\n",
    "            data_err.sort(key=lambda d: d[0] + d[1]) # Sort based on age + 2s error\n",
    "\n",
    "        Y3Zo_cluster, Y3Zo_imax = find_youngest_cluster(data_err, 3)\n",
    "        if sigma == 1:\n",
    "            Y3Zo_WM, Y3Zo_WM_err2s, Y3Zo_WM_MSWD = weightedMean(np.array([d[0] for d in Y3Zo_cluster[:3]]), np.array([d[1] for d in Y3Zo_cluster[:3]]))\n",
    "        if sigma == 2:\n",
    "            Y3Zo_WM, Y3Zo_WM_err2s, Y3Zo_WM_MSWD = weightedMean(np.array([d[0] for d in Y3Zo_cluster[:3]]), np.array([d[1]/2 for d in Y3Zo_cluster[:3]]))\n",
    "        \n",
    "        # Return NaN if Y3Zo did not find a cluster\n",
    "        if Y3Zo_WM == 0.0:\n",
    "            Y3Zo.append([np.nan,np.nan,np.nan])\n",
    "        else:\n",
    "            Y3Zo.append([Y3Zo_WM, Y3Zo_WM_err2s, Y3Zo_WM_MSWD])\n",
    "\n",
    "    return Y3Zo\n",
    "\n",
    "Y3Zo(ages, errors, sigma=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WM     Error      MSWD\n",
      "POR-1  88.558687  1.730722  1.064180\n",
      "POR-2  49.028526  0.654962  0.363433\n",
      "POR-3  87.196365  2.107385  0.331592\n"
     ]
    }
   ],
   "source": [
    "Y3Zo1 = Y3Zo(ages, errors)\n",
    "Y3Zo_Table = pd.DataFrame(data=Y3Zo1, index=[sample_list], columns=['WM', 'Error', 'MSWD'])\n",
    "print(Y3Zo_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Y3Za: Youngest Three Zircons (Y3Za) \n",
    "Calculating a MDA from the weighted average of the youngest three zircons present in the sample (e.g., Zhang et al., 2016). The uncertainty of the MDA calculated by these methods is the uncertainty of the weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[45.640836560294396, 1.543808186463849, 68.11072377529771],\n",
       " [45.831753293688536, 0.8839789922694313, 10.165357131957828],\n",
       " [84.48397901559969, 2.9501827230652267, 17.288675468014766]]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Y3Za(ages, errors):\n",
    "    \"\"\"\n",
    "    Calculates the weighted mean average of the youngest three zircons, regardless of whether they overlap within error (see discussion in Coutts et al. (2019): Geoscience Frontiers)\n",
    "\n",
    "    Parameters\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Y3Za : [the weighted mean age, the 2-sigma uncertainty, and the MSWD]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    Y3Za = []\n",
    "\n",
    "    for i in range(len(ages)):\n",
    "        data_err1s_ageSort = (list(zip(ages[i], errors[i])))\n",
    "        data_err1s_ageSort.sort(key=lambda d: d[0]) # Sort based on age\n",
    "        Y3Za_WM, Y3Za_WMerr2s, Y3Za_WM_MSWD = weightedMean([x[0] for x in data_err1s_ageSort[:3]], [x[1] for x in data_err1s_ageSort[:3]])\n",
    "        if len(ages[i]) < 3: # Return nulls if the samples has less than 3 analyses\n",
    "            Y3Za.append([np.nan,np.nan,np.nan])\n",
    "        else:\n",
    "            Y3Za.append([Y3Za_WM, Y3Za_WMerr2s, Y3Za_WM_MSWD])\n",
    "\n",
    "    return Y3Za\n",
    "\n",
    "Y3Za(ages, errors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WM     Error       MSWD\n",
      "POR-1  45.640837  1.543808  68.110724\n",
      "POR-2  45.831753  0.883979  10.165357\n",
      "POR-3  84.483979  2.950183  17.288675\n"
     ]
    }
   ],
   "source": [
    "Y3Za1 = Y3Za(ages, errors)\n",
    "Y3Za_Table = pd.DataFrame(data=Y3Za1, index=[sample_list], columns=['WM', 'Error', 'MSWD'])\n",
    "print(Y3Za_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. t Method \n",
    "The t method of Barbeau et al. (2009) calculates the weighted average, weighed by date uncertainty, of all dates that fall between the probability minima of the youngest peak composed of a specified number of grains on a probability density function. The number of dates required for a peak to be considered significant varies between studies. In this model we used a minimum of three dates. The uncertainty of the MDA is the uncertainty of the weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[95.59993199414748, 0.6503635895587572, 5.002693363229253, 60],\n",
       " [48.73244647488459, 0.5327683521756137, 2.897368514198844, 7],\n",
       " [92.67830422085191, 0.6294275308238235, 2.158436529270065, 39]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def tauMethod(ages, errors, min_cluster_size=3, thres=0.01, minDist=1, xdif=1, chartOutput = False, x1=0, x2=4000):\n",
    "    \"\"\"\n",
    "    Calculates the tau parameter, which is the mean weighted average of analyses that fall between probability minima (troughs) of a PDP plot (after Barbeau et al. (2009): EPSL)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    min_cluster_size : (optional) the minimum number of analyses to calculate mean weighted average (default = 3)\n",
    "    thres : (optional) threshold of what constitues a peak (from 0 to 1). Default = 0.01\n",
    "    minDist : (optional) minimum distance (Myr) between adjacent peaks. Default = 1\n",
    "    xdif : (optional) bin size to compute PDP (default = 1 Ma)\n",
    "    chartOutput : (optional) set to True to create plots\n",
    "    x1 : (optional) minimum x-axis value (default = 0 Ma)\n",
    "    x2 : (optional) maximum x-axis value (default = 4000 Ma)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tauMethod : [the weighted mean age in Ma, the 2-sigma uncertainty of the weighted mean age, the MSWD of the weighted mean age, and the number of analyses included in the weighted mean age]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    import peakutils\n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]\n",
    "\n",
    "    # Calculate the PDP - note that a small xdif may be desired for increased precision\n",
    "    PDP_age, PDP = PDPcalcAges(ages, errors, xdif)\n",
    "\n",
    "    tauMethod = []\n",
    "    for i in range(len(ages)):  \n",
    "\n",
    "        # Calculate peak indexes\n",
    "        peakIndexes = list(peakutils.indexes(PDP[i], thres=thres, min_dist=minDist))\n",
    "        # Peak ages\n",
    "        peakAges = PDP_age[peakIndexes]\n",
    "        # Number of grains per peak\n",
    "        peakAgeGrain = peakAgesGrains([peakAges], [ages[i]], [errors[i]])[0]\n",
    "\n",
    "        # Calculate trough indexes\n",
    "        troughIndexes = list(peakutils.indexes(PDP[i]*-1, thres=thres, min_dist=minDist))\n",
    "        # Trough ages\n",
    "        troughAges = [0] + list(PDP_age[troughIndexes]) + [4500] # Append a 0 because there is no trough on the young size of the youngest peak and no trough on the old side of the oldest peak\n",
    "\n",
    "        # Zip peak ages and grains per peak\n",
    "        peakAgesGrains_ = list(zip(peakAges, peakAgeGrain))\n",
    "        # Filter out peaks with less than min_cluster_size grains (default is 3, following Barbeau et al., 2009: EPSL)\n",
    "        peakAgesGrainsFiltered = list(filter(lambda x: x[1] >= min_cluster_size, peakAgesGrains_))\n",
    "\n",
    "        # Stop the loop if no peaks are present with the min_cluster_size\n",
    "        if peakAgesGrainsFiltered == []:\n",
    "            tauMethod.append([np.nan, np.nan, np.nan, np.nan])\n",
    "            continue\n",
    "\n",
    "        # Select the nearest trough that is younger than the youngest peak with at least min_cluster_size analyses\n",
    "        troughYoung = np.max(list(filter(lambda x: x < peakAgesGrainsFiltered[0][0], troughAges)))\n",
    "\n",
    "        # Select the nearest trough that is older than the youngest peak with at least min_cluster_size analyses\n",
    "        troughOld = np.min(list(filter(lambda x: x > peakAgesGrainsFiltered[0][0], troughAges)))\n",
    "\n",
    "        # Select ages and errors that fall between troughYoung and troughOld\n",
    "        ages_errors1s = list(zip(ages[i], errors[i]))\n",
    "        ages_errors1s_filtered = list(filter(lambda x: x[0] < troughOld and x[0] > troughYoung, ages_errors1s))\n",
    "\n",
    "        tauMethod_WM, tauMethod_WM_err2s, tauMethod_WM_MSWD = weightedMean(np.array([d[0] for d in ages_errors1s_filtered]), np.array([d[1] for d in ages_errors1s_filtered]))\n",
    "\n",
    "        tauMethod.append([tauMethod_WM, tauMethod_WM_err2s, tauMethod_WM_MSWD, len(ages_errors1s_filtered)])\n",
    "\n",
    "        if chartOutput:\n",
    "            fig, ax = plt.subplots(1)\n",
    "            # Creates a plot output to check results\n",
    "            ax.plot(PDP_age, PDP[i])\n",
    "            ax.plot(PDP_age[peakIndexes], PDP[i][peakIndexes],'o')\n",
    "            ax.plot(PDP_age[troughIndexes], PDP[i][troughIndexes],'o')\n",
    "            ax.plot(tauMethod_WM,0,'s')\n",
    "            ax.plot(ages_errors1s_filtered,np.zeros_like(ages_errors1s_filtered),'s')\n",
    "            #ax.plot(tauMethod_WM-tauMethod_WM_err2s,0,'s')     \n",
    "            ax.set_xlim(0,300)\n",
    "\n",
    "    return tauMethod\n",
    "\n",
    "tauMethod(ages, errors, min_cluster_size=3, thres=0.01, minDist=1, xdif=1, chartOutput = False, x1=0, x2=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WM     Error      MSWD  Grains\n",
      "POR-1  95.599932  0.650364  5.002693      60\n",
      "POR-2  48.732446  0.532768  2.897369       7\n",
      "POR-3  92.678304  0.629428  2.158437      39\n"
     ]
    }
   ],
   "source": [
    "Tau = tauMethod(ages, errors)\n",
    "Tau_Table = pd.DataFrame(data=Tau, index=[sample_list], columns=['WM', 'Error', 'MSWD','Grains'])\n",
    "print(Tau_Table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. YSP: The Youngest Statistical Population\n",
    "Introduced and tested in Coutts et al 2019. The YSP method calculates the MDA as the weighted average of the youngest sub-sample of 2 or more grains that yield a mean square weighted deviation (MSWD) of w1, indicating that the dispersion in the dates is proportional to the uncertainty of the measurements (Wendt and Carl, 1991). To identify the sub-sample of dates used, the MSWD of the youngest two grains is calculated. If acceptable (i.e., <1), an additional grain or additional grains are added until the calculated MSWD exceeds 1. The weighted average of the sub-sample yielding an MSWD closest to 1 is used as the MDA. The uncertainty of the MDA is the uncer- tainty of the weighted average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[91.36513319243302, 0.8898229017135901, 1.0269688740975713, 24],\n",
       " [49.15896935757168, 0.5862219052376383, 1.1401152756563624, 6],\n",
       " [90.30931956325176, 0.9117992703496675, 0.99631854422409, 15]]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def YSP(ages, errors, min_cluster_size=2, MSWD_threshold=1):\n",
    "    \"\"\"\n",
    "    Calculates the youngest statistical population after Coutts et al. (2019): Geoscience Frontiers. The YSP is the weighted average of the youngest group of 2 or more analyses that have a MSWD close to the MSWD_threshold (default=1),\n",
    "    where the the MSWD of the youngest two analyses is less than the MSWD_threshold. The algorithm first considers the youngest two analyses. If they have an MSWD < 1, then a third grain is added and so forth.\n",
    "    The final analyses to be included in the weighted average is the one with the closest value to MSWD_threshold (default of 1).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ages : a 2-D array of ages, len(ages)=number of samples or sample groups\n",
    "    errors : a 2-D array of 1-sigma errors for each sample or sample group, len(errors)=number of samples or sample groups\n",
    "    min_cluster_size : (optional) the minimum number of analyses to calculate a MSWD from (default = 2)\n",
    "    MSWD_threshold : (optional) the MSWD threshold from which to select analyses from\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    YSP : [the weighted mean age in Ma, the 2-sigma uncertainty of the weighted mean age, the MSWD of the weighted mean age, and the number of analyses included in the weighted mean age]\n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    # Check to see if ages is a list of arrays or just a single list of ages\n",
    "    if not hasattr(ages[0], '__len__'):\n",
    "        ages = [ages]\n",
    "        errors = [errors]   \n",
    "\n",
    "    YSP = []\n",
    "    for i in range(len(ages)): # One loop for each sample or sample group\n",
    "        \n",
    "        # Zip ages and errors and sort by age\n",
    "        data_err1s_ageSort = list(zip(ages[i], errors[i]))\n",
    "        data_err1s_ageSort.sort(key=lambda d: d[0]) # Sort based on age\n",
    "        for j in range(len(data_err1s_ageSort)): # One loop for each analysis. Loop repeated if MSWD of the first pair is not <1.\n",
    "\n",
    "            # Creat list of MSWD\n",
    "            MSWD = []\n",
    "            for k in range(len(data_err1s_ageSort)):\n",
    "                MSWD.append(weightedMean(np.array([d[0] for d in data_err1s_ageSort[:(k+2)]]), np.array([d[1] for d in data_err1s_ageSort[:(k+2)]]))[2])\n",
    "\n",
    "            # Add MSWD to the ages & errors tuple   \n",
    "            data_err1s_MSWD = []\n",
    "            for k in range(len(data_err1s_ageSort)):\n",
    "                if k == 0: # Assign the first age an MSWD of 0 (so it is always included in the MSWD)\n",
    "                    data_err1s_MSWD.append((data_err1s_ageSort[k][0], data_err1s_ageSort[k][1], 0))\n",
    "                else: # Assign analyses the MSWD of the previos analysis, such that the filtering returns the correct analyses\n",
    "                    data_err1s_MSWD.append((data_err1s_ageSort[k][0], data_err1s_ageSort[k][1], MSWD[k-1]))\n",
    "\n",
    "            # Need to exit the algorithm if no YSP is found\n",
    "            if j == len(ages[i])-1:\n",
    "                YSP.append([float('nan'), float('nan'), float('nan'), float('nan')])\n",
    "                break\n",
    "\n",
    "            # Find the index of the analysis with an MSWD closest to 1\n",
    "            idx = (np.abs(np.array([d[2] for d in data_err1s_MSWD][1:])-MSWD_threshold)).argmin()+1 # Need to add 1 because we excluded the first one that had an assigned MSWD of 0\n",
    "\n",
    "            # Filter analyses beyond the one which has a MSWD closest to MSWD_threshold\n",
    "            agesFiltered = data_err1s_MSWD[0:idx+1]\n",
    "\n",
    "            YSP_WM, YSP_WM_err2s, YSP_WM_MSWD = weightedMean(np.array([d[0] for d in agesFiltered]), np.array([d[1] for d in agesFiltered]))\n",
    "\n",
    "            if (agesFiltered[1][2] < 1 and len(agesFiltered) >= min_cluster_size): # The first one is excluded because the MSWD is made to be 0. The second youngest analysis must have a MSWD < 1 to proceed. The minimum cluster size must also be met or exceeded.\n",
    "                YSP.append([YSP_WM, YSP_WM_err2s, YSP_WM_MSWD, len(agesFiltered)])\n",
    "                break\n",
    "            else:\n",
    "                del data_err1s_ageSort[0] # Delete the first analysis, which was no use at all, and try again\n",
    "\n",
    "    return YSP\n",
    "\n",
    "YSP(ages, errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              WM     Error      MSWD  Grains\n",
      "POR-1  91.365133  0.889823  1.026969      24\n",
      "POR-2  49.158969  0.586222  1.140115       6\n",
      "POR-3  90.309320  0.911799  0.996319      15\n"
     ]
    }
   ],
   "source": [
    "YSP = YSP(ages, errors)\n",
    "YSP_Table = pd.DataFrame(data=YSP, index=[sample_list], columns=['WM', 'Error', 'MSWD','Grains'])\n",
    "print(YSP_Table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Vermeesh's Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'install' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-d47d66357754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minstall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'IsoplotR'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'install' is not defined"
     ]
    }
   ],
   "source": [
    "install.packages('IsoplotR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. TuffZirc 6+ in Isoplot\n",
    "The TuffZirc algorithm of Ludwig and Mundil (2002) was originally designed to determine the age of ash de- posits and was designed for an input of 12e20 dates (Ludwig and Mundil, 2002). The algorithm has been used to calculate MDAs by inputting the youngest six dates obtained from a sample (Tucker et al., 2013) and is referred to as TuffZirc 6Ã¾. The TuffZirc algorithm first screens the data for â€œhigh uncertainty datesâ€, which may skew the calculation. Then the largest sub-sample of dates that yields a probability-of-fit >0.05 is found (Ludwig and Mundil, 2002). A probability-of-fit >0.05 stipulates that input dates meet the minimum criteria to be derived from a parent population of a single age (within 95% confidence interval) and are dispersed only due to measurement uncertainty (Wendt and Carl, 1991). The al- gorithm then finds the median age of this sub-sample of dates, which is taken as the MDA. The MDA uncertainty is derived from the asymmetric distribution of dates (Ludwig and Mundil, 2002)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AgePick \n",
    "AgePick is a Microsoft Excel!-based application for the interrogation of detrital zircon data. It is used to identify peaks in detrital zircon spectra and to qualitatively screen datasets for inheritance and lead loss (Gehrels, 2003). AgePick does not offer any built-in date-selection criteria for the calculation of MDAs. For the calculation of MDAs, it is typically used to compute the weighted averages of selected dates, or to identify the age of the youngest peak on a probability density plot (i.e., YPP method). While the criteria used to select dates for calculation of weighted averages through AgePick should be stated (e.g., Dickinson and Gehrels, 2009b; Tucker et al., 2013), thorough descriptions of grain-selection criteria are frequently missing in publications. AgePick should not be cited as the MDA calculation method and rather the method of date-selection (e.g., YGC 1s, Y3Z) should be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating Functions\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
